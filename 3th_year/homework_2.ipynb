{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тексты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Канал имени Москвы строили **заключенные**(прилагательное или существительное?) Дмитровского **исправительно-трудового** (дефис) лагеря, который находился в ведении НКВД, поэтому долгое время архивные документы были недоступны. Однако авторы проекта получили доступ к данным документам, благодаря чему они установили изначальную структуру здания, а также определили авторство проекта. По словам Беляева, реставраторам повезло: «В 1990-е людям, возможно, было **лень** (существительное или предикатив?) штукатурить стены, и они просто закрыли их гипсокартоном». **Часовой** (прилагательное или существительное?) механизм на башне заменили на более современный, но на циферблат вернули оригинальные украшения — декоративные накладки в виде солнца. Это легко исправить — современные лампы бывают разных оттенков спектра, и можно подобрать более **подходящий** (причастие от *ходить* или прилагательное?)». Здесь это выполнено **хорошо** (наречие или прилагательное?) и очень деликатно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **lack** (существительное или глагол?) of ethnic diversity at the top of **UK** (аббревиатура) companies is coming under increasing **focus** (существительное или глагол?), with **calls** (существительное или глагол?) for **change** (существительное или глагол?) from big business **groups** (существительное или глагол?) and investors. **Surveys** (существительное или глагол?) continue **to** (частица или предлог?) **show** (существительное или глагол?) that black, Asian, or minority ethnic people are **under-represented** (дефис) in senior positions. But some succeed, and then **turn** (существительное или глагол?) their drive and passion **to** (частица или предлог?) **helping** (отглагольное существительное или герундий?) others. The **BBC** (аббревиатура) has spoken to four of them. But after she **left** (глагол, существительное, прилагательное, наречие?) , she realised she had been altering her personality to \"**fit** (существительное или глагол?) in». But I made an assumption I should be just **like** (глагол, существительное, прилагательное, наречие, предлог, союз? them. If you're black, generally the **experience** (существительное или глагол?) is worse, she says. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Размеченные тексты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{‘Канал’: ‘NOUN’, ‘имени’: ‘NOUN’, ‘Москвы’: ‘NOUN’, ‘строили’: ‘VERB’, ‘заключенные’: ‘NOUN’, ‘Дмитровского’: ‘PROPN’, ‘исправительно’: ‘ADJ’, ‘трудового’: ‘ADJ’,  ‘лагеря’: ‘NOUN’, ‘который’: ‘CONJ’, ‘находился’: ‘VERB’, ‘в’: ‘PREP’, ‘ведении’: ‘NOUN’, ‘НКВД’: ‘NOUN’, ‘поэтому’: ‘CONJ’, ‘долгое’: ‘ADJ’, ‘время’: ‘NOUN’, ‘архивные’: ‘ADJ’, ‘документы’: ‘NOUN’, ‘были’: ‘VERB’, ‘недоступны’: ‘ADJ’, ‘Однако’: ‘ADV’, ‘авторы’: ‘NOUN’, ‘проекта’: ‘NOUN’, ‘получили’: ‘VERB’, ‘доступ’: ‘NOUN’, ‘к’: ‘PREP’, ‘данным’: ‘ADJ’, ‘документам’: ‘NOUN’, ‘благодаря’: ‘CONJ’, ‘чему’: ‘PRON’, ‘они’: ‘PRON’, ‘установили’: ‘VERB’, ‘изначальную’: ‘ADJ’, ‘структуру’: ‘NOUN, ‘здания’: ‘NOUN’, ‘а’: ‘CONJ’, ‘также’: ‘CONJ’ ‘определили’: ‘VERB’, ‘авторство’: ‘NOUN’, ‘проекта’: ‘NOUN’, ‘По’: ‘PREP’, ‘словам’: ‘NOUN’, ‘Беляева’: ‘PROPN’, ‘реставраторам’: ‘NOUN’, ‘повезло’: ‘VERB’, ‘В’: ‘PREP’, ‘1990-е’: ‘NUMR’, ‘людям’: ‘NOUN’, ‘возможно’: ‘ADV’, ‘было’: ‘VERB’, ‘лень’: ‘ADV’, ‘штукатурить’: ‘VERB’, ‘стены’: ‘NOUN’, ‘и’: ‘CONJ’, ‘они’: ‘PRON’, ‘просто’: ‘ADV’, ‘закрыли’: ‘VERB’, ‘их’: PRON’, ‘гипсокартоном’: ‘NOUN’, ‘Часовой’: ‘ADJ’, ‘механизм’: ‘NOUN’, ‘на’: ‘PREP’, ‘башне’: ‘NOUN’, ‘заменили’: ‘VERB’, ‘на’: ‘PREP’, ‘более’: ‘ADV’, ‘современный’: ‘ADJ’, ‘но’: ‘CONJ’, ‘на’: ‘PREP’, ‘циферблат’: ‘NOUN’, 'вернули': ‘VERB’, ‘оригинальные’: ‘ADJ’, ‘украшения’: ‘NOUN’, ‘декоративные’: ‘ADJ’, ‘накладки’: ‘NOUN’, ‘в’: ‘PREP’, ‘виде’: ‘NOUN’, ‘солнца’: ‘NOUN’, ‘Это’: ‘PRON’, ‘легко’: ‘ADV’, ‘исправить’: ‘VERB’, ‘современные’: ‘ADJ’, ‘лампы’: ‘NOUN’, ‘бывают’: ‘VERB’ ‘разных’: ‘ADJ’, ‘оттенков’: ‘NOUN’, ‘спектра’: ‘NOUN’, ‘и’: ‘CONJ’, ‘можно’: ‘AUX’,  ‘подобрать’: ‘VERB’, ‘более’: ‘ADV’, ‘подходящий’: ‘ADJ’, ‘Здесь’: ‘ADV’ ‘это’: ‘PRON’, ‘выполнено’: ‘VERB’, ‘хорошо’: ‘ADV’, ‘и’: ‘CONJ’, ‘очень’: ‘ADV’, ‘деликатно’: ‘ADV’}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{‘The’: ‘DET’, ‘lack’: ‘NOUN’, ‘of’: ‘ADP’, ‘ethnic’: ‘ADJ’, ‘diversity’: ‘NOUN’, ‘at’: ‘ADP’, ‘the’: ‘DET’, ‘top’: ‘NOUN’, ‘of’: ‘ADP’, ‘UK’: ‘PROPN’, ‘companies’: ‘NOUN’, ‘is’: ‘AUX’, ‘coming’: ‘VERB’, ‘under’: ‘ADP’, ‘increasing’: ‘VERB’, ‘focus’: ‘NOUN’, ‘with’: ‘ADP’, ‘calls’: ‘NOUN’, ‘for’: ‘ADP’, ‘change’: ‘NOUN’, ‘from’: ‘ADP’, ‘big’: ‘ADJ’, ‘business’: ‘NOUN’, ‘groups’: ‘NOUN’ ‘and’: ‘CONJ’, ‘investors’: ‘NOUN’, ‘Surveys’: ‘NOUN’, ‘continue’: ‘VERB’, ‘to’: ‘PART’, ‘show’: ‘VERB’, ‘that’: ‘CONJ’, ‘black’: ‘ADJ’, ‘Asian’: ‘ADJ’, ‘or’: ‘CONJ’, ‘minority’: ‘NOUN’, ‘ethnic’: ‘ADJ’, ‘people’: ‘NOUN’, ‘are’: ‘AUX’, ‘under-represented’: ‘VERB’, ‘in’: ‘ADP’, ‘senior’: ‘ADJ’, ‘positions’: ‘NOUN’, ‘But’: ‘CONJ’, ‘some’: ‘PRON’, ‘succeed’: ‘VERB’, ‘and’: ‘CONJ’, ‘then’: ‘ADV’, ‘turn’: ‘VERB’, ‘their’: ‘PRON’, ‘drive’: ‘VERB’, ‘and’: ‘CONJ’, ‘passion’: ‘NOUN’, ‘to’: ‘ADP’, ‘helping’: ‘NOUN’, ‘others’: ‘PRON’, ‘The’: ‘DT’, ‘BBC’: ‘NOUN’, ‘has’: ‘AUX spoken: ‘VERB’, ‘to’: ‘ADP’, ‘four’: ‘NUM’, ‘of’: ‘ADP’, ‘them’: ‘PRON’, ‘But’: ‘CONJ’, ‘after’: ‘ADP’, ‘she’: ‘PRON’, ‘left’: ‘VERB’, ‘she’: ‘PRON’, ‘realised’: ‘VERB’, ‘she’: ‘PRON’, ‘had’: ‘AUX’, ‘been’: ‘AUX’, ‘altering’: ‘VERB’, ‘her’: ‘PRON’, ‘personality’: ‘NOUN’, ‘to’: ‘PART’, ‘fit’: ‘VERB’, ‘in’: ‘ADP’, ‘But’: ‘CONJ’, ‘I’: ‘PRON’, ‘made’: ‘VERB’, ‘an’: ‘DET’, ‘assumption’: ‘VERB’, ‘I’: ‘PRON’, ‘should’: ‘AUX’, ‘be’: ‘VERB’, ‘just’: ‘ADV’, ‘like’: ‘CONJ’, ‘them’: ‘PRON’, ‘If’: ‘CONJ’, ‘you’: ‘PRON’, ‘’re’: ‘VERB’, ‘black’: ‘ADJ’, ‘generally’: ‘ADV’, ‘the’: ‘DET’, ‘experience’: ‘NOUN’, ‘is’: ‘VERB’, ‘worse’: ‘ADJ’, ‘she’: ‘PRON’, ‘says’: ‘VERB’}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rus = 'Канал имени Москвы строили заключенные Дмитровского исправительно-трудового лагеря, который находился в ведении НКВД, поэтому долгое время архивные документы были недоступны. Однако авторы проекта получили доступ к данным документам, благодаря чему они установили изначальную структуру здания, а также определили авторство проекта. По словам Беляева, реставраторам повезло: «В 1990-е людям, возможно, было лень штукатурить стены, и они просто закрыли их гипсокартоном». Часовой механизм на башне заменили на более современный, но на циферблат вернули оригинальные украшения — декоративные накладки в виде солнца. Это легко исправить — современные лампы бывают разных оттенков спектра, и можно подобрать более подходящий». Здесь это выполнено хорошо и очень деликатно.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая делает морфологический разбор с помощью пайморфи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pymorphy(text_rus):\n",
    "    parsed_pymorphy = {}\n",
    "    token = word_tokenize(text_rus)\n",
    "    for word in token:\n",
    "        if word not in \"\"\"!#$%^&*()_+:<>?,./\\|-;\"\"\":\n",
    "            if word != '...' and word != '--':\n",
    "                if word != '``' and word != \"''\":\n",
    "                    ana = morph.parse(word)\n",
    "                    ana = ana[0]\n",
    "                    parsed_pymorphy[word] = ana.tag.POS\n",
    "    return parsed_pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Канал': 'NOUN',\n",
       " 'имени': 'NOUN',\n",
       " 'Москвы': 'NOUN',\n",
       " 'строили': 'VERB',\n",
       " 'заключенные': 'PRTF',\n",
       " 'Дмитровского': 'ADJF',\n",
       " 'исправительно-трудового': 'ADJF',\n",
       " 'лагеря': 'NOUN',\n",
       " 'который': 'ADJF',\n",
       " 'находился': 'VERB',\n",
       " 'в': 'PREP',\n",
       " 'ведении': 'NOUN',\n",
       " 'НКВД': 'NOUN',\n",
       " 'поэтому': 'ADVB',\n",
       " 'долгое': 'ADJF',\n",
       " 'время': 'NOUN',\n",
       " 'архивные': 'ADJF',\n",
       " 'документы': 'NOUN',\n",
       " 'были': 'VERB',\n",
       " 'недоступны': 'ADJS',\n",
       " 'Однако': 'CONJ',\n",
       " 'авторы': 'NOUN',\n",
       " 'проекта': 'NOUN',\n",
       " 'получили': 'VERB',\n",
       " 'доступ': 'NOUN',\n",
       " 'к': 'PREP',\n",
       " 'данным': 'NOUN',\n",
       " 'документам': 'NOUN',\n",
       " 'благодаря': 'PREP',\n",
       " 'чему': 'NPRO',\n",
       " 'они': 'NPRO',\n",
       " 'установили': 'VERB',\n",
       " 'изначальную': 'ADJF',\n",
       " 'структуру': 'NOUN',\n",
       " 'здания': 'NOUN',\n",
       " 'а': 'CONJ',\n",
       " 'также': 'PRCL',\n",
       " 'определили': 'VERB',\n",
       " 'авторство': 'NOUN',\n",
       " 'По': 'PREP',\n",
       " 'словам': 'NOUN',\n",
       " 'Беляева': 'NOUN',\n",
       " 'реставраторам': 'NOUN',\n",
       " 'повезло': 'VERB',\n",
       " '«': None,\n",
       " 'В': 'PREP',\n",
       " '1990-е': 'ADJF',\n",
       " 'людям': 'NOUN',\n",
       " 'возможно': 'CONJ',\n",
       " 'было': 'VERB',\n",
       " 'лень': 'NOUN',\n",
       " 'штукатурить': 'INFN',\n",
       " 'стены': 'NOUN',\n",
       " 'и': 'CONJ',\n",
       " 'просто': 'PRCL',\n",
       " 'закрыли': 'VERB',\n",
       " 'их': 'NPRO',\n",
       " 'гипсокартоном': 'NOUN',\n",
       " '»': None,\n",
       " 'Часовой': 'NOUN',\n",
       " 'механизм': 'NOUN',\n",
       " 'на': 'PREP',\n",
       " 'башне': 'NOUN',\n",
       " 'заменили': 'VERB',\n",
       " 'более': 'ADVB',\n",
       " 'современный': 'ADJF',\n",
       " 'но': 'CONJ',\n",
       " 'циферблат': 'NOUN',\n",
       " 'вернули': 'VERB',\n",
       " 'оригинальные': 'ADJF',\n",
       " 'украшения': 'NOUN',\n",
       " '—': None,\n",
       " 'декоративные': 'ADJF',\n",
       " 'накладки': 'NOUN',\n",
       " 'виде': 'NOUN',\n",
       " 'солнца': 'NOUN',\n",
       " 'Это': 'PRCL',\n",
       " 'легко': 'ADVB',\n",
       " 'исправить': 'INFN',\n",
       " 'современные': 'ADJF',\n",
       " 'лампы': 'NOUN',\n",
       " 'бывают': 'VERB',\n",
       " 'разных': 'ADJF',\n",
       " 'оттенков': 'NOUN',\n",
       " 'спектра': 'NOUN',\n",
       " 'можно': 'PRED',\n",
       " 'подобрать': 'INFN',\n",
       " 'подходящий': 'ADJF',\n",
       " 'Здесь': 'ADVB',\n",
       " 'это': 'PRCL',\n",
       " 'выполнено': 'PRTS',\n",
       " 'хорошо': 'ADVB',\n",
       " 'очень': 'ADVB',\n",
       " 'деликатно': 'ADVB'}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_pymorphy(text_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая делает морфологический разбор с помощью Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mystem(text_rus):\n",
    "    parsed_mystem = {}\n",
    "    ana = m.analyze(text_rus)\n",
    "    for word in ana:\n",
    "        if 'analysis' in word:\n",
    "            gr = word['analysis'][0]['gr']\n",
    "            pos = gr.split('=')[0].split(',')[0]\n",
    "            w = word['text']\n",
    "            parsed_mystem[w] = pos\n",
    "    return parsed_mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Канал': 'S',\n",
       " 'имени': 'S',\n",
       " 'Москвы': 'S',\n",
       " 'строили': 'V',\n",
       " 'заключенные': 'A',\n",
       " 'Дмитровского': 'A',\n",
       " 'исправительно-трудового': 'A',\n",
       " 'лагеря': 'S',\n",
       " 'который': 'APRO',\n",
       " 'находился': 'V',\n",
       " 'в': 'PR',\n",
       " 'ведении': 'S',\n",
       " 'НКВД': 'S',\n",
       " 'поэтому': 'ADVPRO',\n",
       " 'долгое': 'A',\n",
       " 'время': 'S',\n",
       " 'архивные': 'A',\n",
       " 'документы': 'S',\n",
       " 'были': 'V',\n",
       " 'недоступны': 'A',\n",
       " 'Однако': 'CONJ',\n",
       " 'авторы': 'S',\n",
       " 'проекта': 'S',\n",
       " 'получили': 'V',\n",
       " 'доступ': 'S',\n",
       " 'к': 'PR',\n",
       " 'данным': 'A',\n",
       " 'документам': 'S',\n",
       " 'благодаря': 'PR',\n",
       " 'чему': 'SPRO',\n",
       " 'они': 'SPRO',\n",
       " 'установили': 'V',\n",
       " 'изначальную': 'A',\n",
       " 'структуру': 'S',\n",
       " 'здания': 'S',\n",
       " 'а': 'CONJ',\n",
       " 'также': 'ADV',\n",
       " 'определили': 'V',\n",
       " 'авторство': 'S',\n",
       " 'По': 'PR',\n",
       " 'словам': 'S',\n",
       " 'Беляева': 'S',\n",
       " 'реставраторам': 'S',\n",
       " 'повезло': 'V',\n",
       " 'В': 'S',\n",
       " 'е': 'S',\n",
       " 'людям': 'S',\n",
       " 'возможно': 'ADV',\n",
       " 'было': 'V',\n",
       " 'лень': 'ADV',\n",
       " 'штукатурить': 'V',\n",
       " 'стены': 'S',\n",
       " 'и': 'CONJ',\n",
       " 'просто': 'PART',\n",
       " 'закрыли': 'V',\n",
       " 'их': 'APRO',\n",
       " 'гипсокартоном': 'S',\n",
       " 'Часовой': 'A',\n",
       " 'механизм': 'S',\n",
       " 'на': 'PR',\n",
       " 'башне': 'S',\n",
       " 'заменили': 'V',\n",
       " 'более': 'ADV',\n",
       " 'современный': 'A',\n",
       " 'но': 'CONJ',\n",
       " 'циферблат': 'S',\n",
       " 'вернули': 'V',\n",
       " 'оригинальные': 'A',\n",
       " 'украшения': 'S',\n",
       " 'декоративные': 'A',\n",
       " 'накладки': 'S',\n",
       " 'виде': 'S',\n",
       " 'солнца': 'S',\n",
       " 'Это': 'SPRO',\n",
       " 'легко': 'ADV',\n",
       " 'исправить': 'V',\n",
       " 'современные': 'A',\n",
       " 'лампы': 'S',\n",
       " 'бывают': 'V',\n",
       " 'разных': 'A',\n",
       " 'оттенков': 'S',\n",
       " 'спектра': 'S',\n",
       " 'можно': 'ADV',\n",
       " 'подобрать': 'V',\n",
       " 'подходящий': 'A',\n",
       " 'Здесь': 'ADVPRO',\n",
       " 'это': 'SPRO',\n",
       " 'выполнено': 'V',\n",
       " 'хорошо': 'ADV',\n",
       " 'очень': 'ADV',\n",
       " 'деликатно': 'ADV'}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_mystem(text_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая делает морфологический разбор с помощью Наташи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_natasha(text_rus):\n",
    "    parsed_natasha = {}\n",
    "    doc = Doc(text_rus)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        parsed_natasha[token.text] = token.pos\n",
    "    return parsed_natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Канал': 'NOUN',\n",
       " 'имени': 'NOUN',\n",
       " 'Москвы': 'PROPN',\n",
       " 'строили': 'VERB',\n",
       " 'заключенные': 'NOUN',\n",
       " 'Дмитровского': 'ADJ',\n",
       " 'исправительно-трудового': 'ADJ',\n",
       " 'лагеря': 'NOUN',\n",
       " ',': 'PUNCT',\n",
       " 'который': 'PRON',\n",
       " 'находился': 'VERB',\n",
       " 'в': 'ADP',\n",
       " 'ведении': 'NOUN',\n",
       " 'НКВД': 'PROPN',\n",
       " 'поэтому': 'ADV',\n",
       " 'долгое': 'ADJ',\n",
       " 'время': 'NOUN',\n",
       " 'архивные': 'ADJ',\n",
       " 'документы': 'NOUN',\n",
       " 'были': 'AUX',\n",
       " 'недоступны': 'ADJ',\n",
       " '.': 'PUNCT',\n",
       " 'Однако': 'ADV',\n",
       " 'авторы': 'NOUN',\n",
       " 'проекта': 'NOUN',\n",
       " 'получили': 'VERB',\n",
       " 'доступ': 'NOUN',\n",
       " 'к': 'ADP',\n",
       " 'данным': 'ADJ',\n",
       " 'документам': 'NOUN',\n",
       " 'благодаря': 'ADP',\n",
       " 'чему': 'PRON',\n",
       " 'они': 'PRON',\n",
       " 'установили': 'VERB',\n",
       " 'изначальную': 'ADJ',\n",
       " 'структуру': 'NOUN',\n",
       " 'здания': 'NOUN',\n",
       " 'а': 'CCONJ',\n",
       " 'также': 'ADV',\n",
       " 'определили': 'VERB',\n",
       " 'авторство': 'NOUN',\n",
       " 'По': 'ADP',\n",
       " 'словам': 'NOUN',\n",
       " 'Беляева': 'PROPN',\n",
       " 'реставраторам': 'NOUN',\n",
       " 'повезло': 'VERB',\n",
       " ':': 'PUNCT',\n",
       " '«': 'PUNCT',\n",
       " 'В': 'ADP',\n",
       " '1990-е': 'NUM',\n",
       " 'людям': 'NOUN',\n",
       " 'возможно': 'ADV',\n",
       " 'было': 'AUX',\n",
       " 'лень': 'VERB',\n",
       " 'штукатурить': 'ADJ',\n",
       " 'стены': 'NOUN',\n",
       " 'и': 'CCONJ',\n",
       " 'просто': 'PART',\n",
       " 'закрыли': 'VERB',\n",
       " 'их': 'PRON',\n",
       " 'гипсокартоном': 'NOUN',\n",
       " '»': 'PUNCT',\n",
       " 'Часовой': 'ADJ',\n",
       " 'механизм': 'NOUN',\n",
       " 'на': 'ADP',\n",
       " 'башне': 'NOUN',\n",
       " 'заменили': 'VERB',\n",
       " 'более': 'ADV',\n",
       " 'современный': 'ADJ',\n",
       " 'но': 'CCONJ',\n",
       " 'циферблат': 'NOUN',\n",
       " 'вернули': 'VERB',\n",
       " 'оригинальные': 'ADJ',\n",
       " 'украшения': 'NOUN',\n",
       " '—': 'PUNCT',\n",
       " 'декоративные': 'ADJ',\n",
       " 'накладки': 'NOUN',\n",
       " 'виде': 'NOUN',\n",
       " 'солнца': 'NOUN',\n",
       " 'Это': 'PRON',\n",
       " 'легко': 'ADJ',\n",
       " 'исправить': 'VERB',\n",
       " 'современные': 'ADJ',\n",
       " 'лампы': 'NOUN',\n",
       " 'бывают': 'VERB',\n",
       " 'разных': 'ADJ',\n",
       " 'оттенков': 'NOUN',\n",
       " 'спектра': 'NOUN',\n",
       " 'можно': 'ADV',\n",
       " 'подобрать': 'VERB',\n",
       " 'подходящий': 'ADJ',\n",
       " 'Здесь': 'ADV',\n",
       " 'это': 'PRON',\n",
       " 'выполнено': 'VERB',\n",
       " 'хорошо': 'ADV',\n",
       " 'очень': 'ADV',\n",
       " 'деликатно': 'ADV'}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_natasha(text_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "print(len(parsed_text_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_eng = \"\"\"The lack of ethnic diversity at the top of UK companies is coming under increasing focus, with calls for change from big business groups and investors. Surveys continue to show that black, Asian, or minority ethnic people are under-represented in senior positions. But some succeed, and then turn their drive and passion to helping others. The BBC has spoken to four of them. But after she left, she realised she had been altering her personality to \"fit in». But I made an assumption I should be just like them. If you're black, generally the experience is worse, she says.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая делает морфологический разбор английского текста с помощью SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_spacy(text_eng):\n",
    "    parsed_spacy = {}\n",
    "    nlp = en_core_web_sm.load()\n",
    "    doc = nlp(text_eng)\n",
    "    for i, s in enumerate(doc.sents):\n",
    "        for t in s:\n",
    "            parsed_spacy[t.text] = t.pos_\n",
    "    return parsed_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 'DET',\n",
       " 'lack': 'NOUN',\n",
       " 'of': 'ADP',\n",
       " 'ethnic': 'ADJ',\n",
       " 'diversity': 'NOUN',\n",
       " 'at': 'ADP',\n",
       " 'the': 'DET',\n",
       " 'top': 'NOUN',\n",
       " 'UK': 'PROPN',\n",
       " 'companies': 'NOUN',\n",
       " 'is': 'AUX',\n",
       " 'coming': 'VERB',\n",
       " 'under': 'ADV',\n",
       " 'increasing': 'VERB',\n",
       " 'focus': 'NOUN',\n",
       " ',': 'PUNCT',\n",
       " 'with': 'ADP',\n",
       " 'calls': 'NOUN',\n",
       " 'for': 'ADP',\n",
       " 'change': 'NOUN',\n",
       " 'from': 'ADP',\n",
       " 'big': 'ADJ',\n",
       " 'business': 'NOUN',\n",
       " 'groups': 'NOUN',\n",
       " 'and': 'CCONJ',\n",
       " 'investors': 'NOUN',\n",
       " '.': 'PUNCT',\n",
       " 'Surveys': 'NOUN',\n",
       " 'continue': 'VERB',\n",
       " 'to': 'PART',\n",
       " 'show': 'VERB',\n",
       " 'that': 'SCONJ',\n",
       " 'black': 'ADJ',\n",
       " 'Asian': 'ADJ',\n",
       " 'or': 'CCONJ',\n",
       " 'minority': 'NOUN',\n",
       " 'people': 'NOUN',\n",
       " 'are': 'AUX',\n",
       " '-': 'PUNCT',\n",
       " 'represented': 'VERB',\n",
       " 'in': 'ADP',\n",
       " 'senior': 'ADJ',\n",
       " 'positions': 'NOUN',\n",
       " 'But': 'CCONJ',\n",
       " 'some': 'DET',\n",
       " 'succeed': 'VERB',\n",
       " 'then': 'ADV',\n",
       " 'turn': 'VERB',\n",
       " 'their': 'DET',\n",
       " 'drive': 'NOUN',\n",
       " 'passion': 'NOUN',\n",
       " 'helping': 'VERB',\n",
       " 'others': 'NOUN',\n",
       " 'BBC': 'PROPN',\n",
       " 'has': 'AUX',\n",
       " 'spoken': 'VERB',\n",
       " 'four': 'NUM',\n",
       " 'them': 'PRON',\n",
       " 'after': 'ADP',\n",
       " 'she': 'PRON',\n",
       " 'left': 'VERB',\n",
       " 'realised': 'VERB',\n",
       " 'had': 'AUX',\n",
       " 'been': 'AUX',\n",
       " 'altering': 'VERB',\n",
       " 'her': 'DET',\n",
       " 'personality': 'NOUN',\n",
       " '\"': 'PUNCT',\n",
       " 'fit': 'VERB',\n",
       " '»': 'X',\n",
       " 'I': 'PRON',\n",
       " 'made': 'VERB',\n",
       " 'an': 'DET',\n",
       " 'assumption': 'NOUN',\n",
       " 'should': 'VERB',\n",
       " 'be': 'AUX',\n",
       " 'just': 'ADV',\n",
       " 'like': 'SCONJ',\n",
       " 'If': 'SCONJ',\n",
       " 'you': 'PRON',\n",
       " \"'re\": 'AUX',\n",
       " 'generally': 'ADV',\n",
       " 'experience': 'NOUN',\n",
       " 'worse': 'ADJ',\n",
       " 'says': 'VERB'}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_spacy(text_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-18 15:53:52,949 loading file /Users/kseniapetuhova/.flair/models/en-pos-ontonotes-v0.5.pt\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая делает морфологический разбор с помощью Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_flair(text_eng):\n",
    "    parsed_flair = {}\n",
    "    sentence = Sentence(text_eng)\n",
    "    tagger.predict(sentence)\n",
    "    a = sentence.to_tagged_string()\n",
    "    list_a = a.split(' ')\n",
    "    for i in range(len(list_a)):\n",
    "        if i % 2 == 0:\n",
    "            x = list_a[i]\n",
    "            y = list_a[i+1]\n",
    "            parsed_flair[x] = y\n",
    "    return parsed_flair    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': '<DT>',\n",
       " 'lack': '<NN>',\n",
       " 'of': '<IN>',\n",
       " 'ethnic': '<JJ>',\n",
       " 'diversity': '<NN>',\n",
       " 'at': '<IN>',\n",
       " 'the': '<DT>',\n",
       " 'top': '<NN>',\n",
       " 'UK': '<NNP>',\n",
       " 'companies': '<NNS>',\n",
       " 'is': '<VBZ>',\n",
       " 'coming': '<VBG>',\n",
       " 'under': '<IN>',\n",
       " 'increasing': '<VBG>',\n",
       " 'focus': '<NN>',\n",
       " ',': '<,>',\n",
       " 'with': '<IN>',\n",
       " 'calls': '<NNS>',\n",
       " 'for': '<IN>',\n",
       " 'change': '<NN>',\n",
       " 'from': '<IN>',\n",
       " 'big': '<JJ>',\n",
       " 'business': '<NN>',\n",
       " 'groups': '<NNS>',\n",
       " 'and': '<CC>',\n",
       " 'investors': '<NNS>',\n",
       " '.': '<.>',\n",
       " 'Surveys': '<NNS>',\n",
       " 'continue': '<VBP>',\n",
       " 'to': '<TO>',\n",
       " 'show': '<VB>',\n",
       " 'that': '<IN>',\n",
       " 'black': '<JJ>',\n",
       " 'Asian': '<JJ>',\n",
       " 'or': '<CC>',\n",
       " 'minority': '<NN>',\n",
       " 'people': '<NNS>',\n",
       " 'are': '<VBP>',\n",
       " 'under-represented': '<VBN>',\n",
       " 'in': '<RP>',\n",
       " 'senior': '<JJ>',\n",
       " 'positions': '<NNS>',\n",
       " 'But': '<CC>',\n",
       " 'some': '<DT>',\n",
       " 'succeed': '<VBP>',\n",
       " 'then': '<RB>',\n",
       " 'turn': '<VBP>',\n",
       " 'their': '<PRP$>',\n",
       " 'drive': '<NN>',\n",
       " 'passion': '<NN>',\n",
       " 'helping': '<VBG>',\n",
       " 'others': '<NNS>',\n",
       " 'BBC': '<NNP>',\n",
       " 'has': '<VBZ>',\n",
       " 'spoken': '<VBN>',\n",
       " 'four': '<CD>',\n",
       " 'them': '<PRP>',\n",
       " 'after': '<IN>',\n",
       " 'she': '<PRP>',\n",
       " 'left': '<VBD>',\n",
       " 'realised': '<VBD>',\n",
       " 'had': '<VBD>',\n",
       " 'been': '<VBN>',\n",
       " 'altering': '<VBG>',\n",
       " 'her': '<PRP$>',\n",
       " 'personality': '<NN>',\n",
       " '\"': '<``>',\n",
       " 'fit': '<VB>',\n",
       " '»': '<:>',\n",
       " 'I': '<PRP>',\n",
       " 'made': '<VBD>',\n",
       " 'an': '<DT>',\n",
       " 'assumption': '<NN>',\n",
       " 'should': '<MD>',\n",
       " 'be': '<VB>',\n",
       " 'just': '<RB>',\n",
       " 'like': '<IN>',\n",
       " 'If': '<IN>',\n",
       " 'you': '<PRP>',\n",
       " \"'re\": '<VBP>',\n",
       " 'generally': '<RB>',\n",
       " 'experience': '<NN>',\n",
       " 'worse': '<JJR>',\n",
       " 'says': '<VBZ>'}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_flair(text_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая делает морфологический разбор с помощью NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nltk(text_eng):\n",
    "    parsed_nltk = {}\n",
    "    sentences = sent_tokenize(text_eng)\n",
    "    for sent in sentences:\n",
    "        tokens = word_tokenize(sent)\n",
    "        tagged = nltk.pos_tag(tokens)\n",
    "        for token in tagged:\n",
    "            parsed_nltk[token[0]] = token[1]\n",
    "    return parsed_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 'DT',\n",
       " 'lack': 'NN',\n",
       " 'of': 'IN',\n",
       " 'ethnic': 'JJ',\n",
       " 'diversity': 'NN',\n",
       " 'at': 'IN',\n",
       " 'the': 'DT',\n",
       " 'top': 'NN',\n",
       " 'UK': 'NNP',\n",
       " 'companies': 'NNS',\n",
       " 'is': 'VBZ',\n",
       " 'coming': 'VBG',\n",
       " 'under': 'IN',\n",
       " 'increasing': 'VBG',\n",
       " 'focus': 'NN',\n",
       " ',': ',',\n",
       " 'with': 'IN',\n",
       " 'calls': 'NNS',\n",
       " 'for': 'IN',\n",
       " 'change': 'NN',\n",
       " 'from': 'IN',\n",
       " 'big': 'JJ',\n",
       " 'business': 'NN',\n",
       " 'groups': 'NNS',\n",
       " 'and': 'CC',\n",
       " 'investors': 'NNS',\n",
       " '.': '.',\n",
       " 'Surveys': 'NNS',\n",
       " 'continue': 'VBP',\n",
       " 'to': 'TO',\n",
       " 'show': 'VB',\n",
       " 'that': 'DT',\n",
       " 'black': 'JJ',\n",
       " 'Asian': 'JJ',\n",
       " 'or': 'CC',\n",
       " 'minority': 'NN',\n",
       " 'people': 'NNS',\n",
       " 'are': 'VBP',\n",
       " 'under-represented': 'JJ',\n",
       " 'in': 'IN',\n",
       " 'senior': 'JJ',\n",
       " 'positions': 'NNS',\n",
       " 'But': 'CC',\n",
       " 'some': 'DT',\n",
       " 'succeed': 'VB',\n",
       " 'then': 'RB',\n",
       " 'turn': 'VB',\n",
       " 'their': 'PRP$',\n",
       " 'drive': 'NN',\n",
       " 'passion': 'NN',\n",
       " 'helping': 'VBG',\n",
       " 'others': 'NNS',\n",
       " 'BBC': 'NNP',\n",
       " 'has': 'VBZ',\n",
       " 'spoken': 'VBN',\n",
       " 'four': 'CD',\n",
       " 'them': 'PRP',\n",
       " 'after': 'IN',\n",
       " 'she': 'PRP',\n",
       " 'left': 'VBD',\n",
       " 'realised': 'VBD',\n",
       " 'had': 'VBD',\n",
       " 'been': 'VBN',\n",
       " 'altering': 'VBG',\n",
       " 'her': 'PRP$',\n",
       " 'personality': 'NN',\n",
       " '``': '``',\n",
       " 'fit': 'VB',\n",
       " '»': 'NN',\n",
       " 'I': 'PRP',\n",
       " 'made': 'VBD',\n",
       " 'an': 'DT',\n",
       " 'assumption': 'NN',\n",
       " 'should': 'MD',\n",
       " 'be': 'VB',\n",
       " 'just': 'RB',\n",
       " 'like': 'IN',\n",
       " 'If': 'IN',\n",
       " 'you': 'PRP',\n",
       " \"'re\": 'VBP',\n",
       " 'generally': 'RB',\n",
       " 'experience': 'NN',\n",
       " 'worse': 'JJR',\n",
       " 'says': 'VBZ'}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_nltk(text_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая приводит формат разметки пайморфи к моему формату разметки и считает точность разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_pymorphy(parsed_text_rus, parsed_pymorphy):\n",
    "    equal_tags_pymorphy = {}\n",
    "    results = []\n",
    "    gold = []\n",
    "    for key in parsed_pymorphy.keys():\n",
    "        if parsed_pymorphy[key] == 'ADJF' or parsed_pymorphy[key] == 'ADJS':\n",
    "            equal_tags_pymorphy[key] = 'ADJ'\n",
    "        elif parsed_pymorphy[key] == 'NPRO':\n",
    "            equal_tags_pymorphy[key] = 'PRON'\n",
    "        elif parsed_pymorphy[key] == 'INFN':\n",
    "            equal_tags_pymorphy[key] = 'VERB'\n",
    "        elif parsed_pymorphy[key] == 'ADVB':\n",
    "            equal_tags_pymorphy[key] = 'ADV'     \n",
    "        else:\n",
    "            equal_tags_pymorphy[key] = parsed_pymorphy[key]\n",
    "    \n",
    "    for key in parsed_text_rus.keys():\n",
    "        gold.append(parsed_text_rus[key])\n",
    "        if key in equal_tags_pymorphy.keys():\n",
    "            results.append(equal_tags_pymorphy[key])\n",
    "        else: \n",
    "            results.append('None')\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_mystem(parsed_text_rus, parsed_mystem):\n",
    "    equal_tags_mystem = {}\n",
    "    results = []\n",
    "    gold = []\n",
    "    for key in parsed_mystem.keys():\n",
    "        if parsed_mystem[key] == 'S':\n",
    "            equal_tags_mystem[key] = 'NOUN'\n",
    "        elif parsed_mystem[key] == 'V':\n",
    "            equal_tags_mystem[key] = 'VERB'\n",
    "        elif parsed_mystem[key] == 'A':\n",
    "            equal_tags_mystem[key] = 'ADJ'\n",
    "        elif parsed_mystem[key] == 'APRO' or parsed_mystem[key] == 'SPRO':\n",
    "            equal_tags_mystem[key] = 'PRON'\n",
    "        elif parsed_mystem[key] == 'PR':\n",
    "            equal_tags_mystem[key] = 'PREP'\n",
    "        elif parsed_mystem[key] == 'ADVPRO':\n",
    "            equal_tags_mystem[key] = 'ADV'\n",
    "        elif parsed_mystem[key] == 'PART':\n",
    "            equal_tags_mystem[key] = 'PRCL'\n",
    "        else:\n",
    "            equal_tags_mystem[key] = parsed_mystem[key]\n",
    "            \n",
    "    for key in parsed_text_rus.keys():\n",
    "        gold.append(parsed_text_rus[key])\n",
    "        if key in equal_tags_mystem.keys():\n",
    "            results.append(equal_tags_mystem[key])\n",
    "        else:\n",
    "            results.append('None')\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_natasha(parsed_text_rus, parsed_natasha):\n",
    "    results = []\n",
    "    gold = []\n",
    "    for key in parsed_text_rus.keys():\n",
    "        gold.append(parsed_text_rus[key])\n",
    "        if key in parsed_natasha.keys():\n",
    "            results.append(parsed_natasha[key])\n",
    "        else:\n",
    "            results.append('None')\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_spacy(parsed_text_eng, parsed_spacy):\n",
    "    results = []\n",
    "    gold = []\n",
    "    for key in parsed_text_eng.keys():\n",
    "        gold.append(parsed_text_eng[key])\n",
    "        if key in parsed_spacy.keys():\n",
    "            results.append(parsed_spacy[key])\n",
    "        else:\n",
    "            results.append('None')\n",
    "    \n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_flair(parsed_text_eng, parsed_flair):\n",
    "    equal_tags_flair = {}\n",
    "    results = []\n",
    "    gold = []\n",
    "    for key in parsed_flair.keys():\n",
    "        if parsed_flair[key] == '<DT>':\n",
    "            equal_tags_flair[key] = 'DET'\n",
    "        elif parsed_flair[key] == '<NN>' or parsed_flair[key] == '<NNS>':\n",
    "            equal_tags_flair[key] = 'NOUN'\n",
    "        elif parsed_flair[key] == '<IN>' or parsed_flair[key] == '<RP>':\n",
    "            equal_tags_flair[key] = 'ADP'\n",
    "        elif parsed_flair[key] == '<JJ>' or parsed_flair[key] == '<JJR>':\n",
    "            equal_tags_flair[key] = 'ADJ'\n",
    "        elif parsed_flair[key] == '<NNP>':\n",
    "            equal_tags_flair[key] = 'PROPN'\n",
    "        elif parsed_flair[key] == '<VBZ>' or parsed_flair[key] == '<VBG>' or parsed_flair[key] == '<VBP>':\n",
    "            equal_tags_flair[key] = 'VERB'\n",
    "        elif parsed_flair[key] == '<CC>':\n",
    "            equal_tags_flair[key] = 'CCONJ'\n",
    "        elif parsed_flair[key] == '<TO>':\n",
    "            equal_tags_flair[key] = 'PART'\n",
    "        elif parsed_flair[key] == '<VB>' or parsed_flair[key] == '<VBN>' or parsed_flair[key] == '<VBD>':\n",
    "            equal_tags_flair[key] = 'VERB'\n",
    "        elif parsed_flair[key] == '<RB>':\n",
    "            equal_tags_flair[key] = 'ADV'\n",
    "        elif parsed_flair[key] == '<PRP$>' or parsed_flair[key] == '<PRP>':\n",
    "            equal_tags_flair[key] = 'PRON'\n",
    "        elif parsed_flair[key] == '<CD>':\n",
    "            equal_tags_flair[key] = 'NUM'\n",
    "        elif parsed_flair[key] == '<MD>':\n",
    "            equal_tags_flair[key] = 'AUX'\n",
    "        else:\n",
    "            equal_tags_flair[key] = parsed_flair[key]\n",
    "    \n",
    "    for key in parsed_text_eng.keys():\n",
    "        gold.append(parsed_text_eng[key])\n",
    "        if key in equal_tags_flair.keys():\n",
    "            results.append(equal_tags_flair[key])\n",
    "        else:\n",
    "            results.append('None')\n",
    "    \n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_nltk(parsed_text_eng, parsed_nltk):\n",
    "    equal_tags_nltk = {}\n",
    "    results = []\n",
    "    gold = []\n",
    "    for key in parsed_nltk.keys():\n",
    "        if parsed_nltk[key] == 'DT':\n",
    "            equal_tags_nltk[key] = 'DET'\n",
    "        elif parsed_nltk[key] == 'NN' or parsed_nltk[key] == 'NNS':\n",
    "            equal_tags_nltk[key] = 'NOUN'\n",
    "        elif parsed_nltk[key] == 'IN':\n",
    "            equal_tags_nltk[key] = 'ADP'\n",
    "        elif parsed_nltk[key] == 'JJ' or parsed_nltk[key] == 'JJR':\n",
    "            equal_tags_nltk[key] = 'ADJ'\n",
    "        elif parsed_nltk[key] == 'NNP':\n",
    "            equal_tags_nltk[key] = 'PROPN'\n",
    "        elif parsed_nltk[key] == 'VBZ' or parsed_nltk[key] == 'VBG' or parsed_nltk[key] == 'VBP':\n",
    "            equal_tags_nltk[key] = 'VERB'\n",
    "        elif parsed_nltk[key] == 'CC':\n",
    "            equal_tags_nltk[key] = 'CCONJ'\n",
    "        elif parsed_nltk[key] == 'TO':\n",
    "            equal_tags_nltk[key] = 'PART'\n",
    "        elif parsed_nltk[key] == 'VB':\n",
    "            equal_tags_nltk[key] = 'VERB'\n",
    "        elif parsed_nltk[key] == 'RB':\n",
    "            equal_tags_nltk[key] = 'ADV'\n",
    "        elif parsed_nltk[key] == 'PRP$' or parsed_nltk[key] == 'PRP':\n",
    "            equal_tags_nltk[key] = 'PRON'\n",
    "        elif parsed_nltk[key] == 'CD':\n",
    "            equal_tags_nltk[key] = 'NUM'\n",
    "        elif parsed_nltk[key] == 'MD':\n",
    "            equal_tags_nltk[key] = 'AUX'\n",
    "        else:\n",
    "            equal_tags_nltk[key] = parsed_nltk[key]\n",
    "        \n",
    "    for key in parsed_text_eng.keys():\n",
    "        gold.append(parsed_text_eng[key])\n",
    "        if key in equal_tags_nltk.keys():\n",
    "            results.append(equal_tags_nltk[key])\n",
    "        else:\n",
    "            results.append('None')\n",
    "    \n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    text_rus = 'Канал имени Москвы строили заключенные Дмитровского исправительно-трудового лагеря, который находился в ведении НКВД, поэтому долгое время архивные документы были недоступны. Однако авторы проекта получили доступ к данным документам, благодаря чему они установили изначальную структуру здания, а также определили авторство проекта. По словам Беляева, реставраторам повезло: «В 1990-е людям, возможно, было лень штукатурить стены, и они просто закрыли их гипсокартоном». Часовой механизм на башне заменили на более современный, но на циферблат вернули оригинальные украшения — декоративные накладки в виде солнца. Это легко исправить — современные лампы бывают разных оттенков спектра, и можно подобрать более подходящий». Здесь это выполнено хорошо и очень деликатно.'\n",
    "    text_eng = \"\"\"The lack of ethnic diversity at the top of UK companies is coming under increasing focus, with calls for change from big business groups and investors. Surveys continue to show that black, Asian, or minority ethnic people are under-represented in senior positions. But some succeed, and then turn their drive and passion to helping others. The BBC has spoken to four of them. But after she left, she realised she had been altering her personality to \"fit in». But I made an assumption I should be just like them. If you're black, generally the experience is worse, she says.\"\"\"\n",
    "    q = parse_pymorphy(text_rus)\n",
    "    w = parse_mystem(text_rus)\n",
    "    e = parse_natasha(text_rus)\n",
    "    r = parse_spacy(text_eng)\n",
    "    t = parse_flair(text_eng)\n",
    "    y = parse_nltk(text_eng)\n",
    "    parsed_text_rus = {'Канал': 'NOUN', 'имени': 'NOUN', 'Москвы': 'NOUN', 'строили': 'VERB',\n",
    "                   'заключенные': 'NOUN', 'Дмитровского': 'PROPN', 'исправительно-трудового': 'ADJ',\n",
    "                   'лагеря': 'NOUN', 'который': 'CONJ', 'находился': 'VERB',\n",
    "                   'в': 'PREP', 'ведении': 'NOUN', 'НКВД': 'NOUN', 'поэтому': 'CONJ', 'долгое': 'ADJ',\n",
    "                   'время': 'NOUN', 'архивные': 'ADJ', 'документы': 'NOUN', 'были': 'VERB',\n",
    "                   'недоступны': 'ADJ', 'Однако': 'CONJ', 'авторы': 'NOUN', 'проекта': 'NOUN',\n",
    "                   'получили': 'VERB', 'доступ': 'NOUN', 'к': 'PREP', 'данным': 'ADJ', 'документам': 'NOUN',\n",
    "                   'благодаря': 'PREP', 'чему': 'PRON', 'они': 'PRON', 'установили': 'VERB',\n",
    "                   'изначальную': 'ADJ', 'структуру': 'NOUN', 'здания': 'NOUN', 'а': 'CONJ', 'также': 'CONJ',\n",
    "                   'определили': 'VERB', 'авторство': 'NOUN', 'проекта': 'NOUN', 'По': 'PREP', 'словам': 'NOUN',\n",
    "                   'Беляева': 'PROPN', 'реставраторам': 'NOUN', 'повезло': 'VERB', 'В': 'PREP',\n",
    "                   '1990-е': 'NUMR', 'людям': 'NOUN', 'возможно': 'ADV', 'было': 'VERB', 'лень': 'ADV',\n",
    "                   'штукатурить': 'VERB', 'стены': 'NOUN', 'и': 'CONJ', 'они': 'PRON', 'просто': 'PRCL',\n",
    "                   'закрыли': 'VERB', 'их': 'PRON', 'гипсокартоном': 'NOUN', 'Часовой': 'ADJ',\n",
    "                   'механизм': 'NOUN', 'на': 'PREP', 'башне': 'NOUN', 'заменили': 'VERB', 'на': 'PREP',\n",
    "                   'более': 'ADV', 'современный': 'ADJ', 'но': 'CONJ', 'на': 'PREP', 'циферблат': 'NOUN',\n",
    "                   'вернули': 'VERB', 'оригинальные': 'ADJ', 'украшения': 'NOUN', 'декоративные': 'ADJ',\n",
    "                   'накладки': 'NOUN', 'в': 'PREP', 'виде': 'NOUN', 'солнца': 'NOUN', 'Это': 'PRON',\n",
    "                   'легко': 'ADV', 'исправить': 'VERB', 'современные': 'ADJ', 'лампы': 'NOUN',\n",
    "                   'бывают': 'VERB', 'разных': 'ADJ', 'оттенков': 'NOUN', 'спектра': 'NOUN',\n",
    "                   'и': 'CONJ', 'можно': 'AUX',  'подобрать': 'VERB', 'более': 'ADV',\n",
    "                   'подходящий': 'ADJ', 'Здесь': 'ADV', 'это': 'PRON', 'выполнено': 'VERB',\n",
    "                   'хорошо': 'ADV', 'и': 'CONJ', 'очень': 'ADV', 'деликатно': 'ADV'}\n",
    "    print('Оценка разбора Pymorphy2')\n",
    "    u = accuracy_pymorphy(parsed_text_rus, q)\n",
    "    print('########################')\n",
    "    print('Оценка разбора Mystem')\n",
    "    i = accuracy_mystem(parsed_text_rus, w)\n",
    "    print('########################')\n",
    "    print('Оценка разбора Natasha')\n",
    "    o = accuracy_natasha(parsed_text_rus, e)\n",
    "    print('########################')\n",
    "    parsed_text_eng = {'The': 'DET', 'lack': 'NOUN', 'of': 'ADP', 'ethnic': 'ADJ',\n",
    "                   'diversity': 'NOUN', 'at': 'ADP', 'the': 'DET', 'top': 'NOUN', 'of': 'ADP',\n",
    "                   'UK': 'PROPN', 'companies': 'NOUN', 'is': 'AUX', 'coming': 'VERB', 'under': 'ADP',\n",
    "                   'increasing': 'VERB', 'focus': 'NOUN', 'with': 'ADP', 'calls': 'NOUN', 'for': 'ADP',\n",
    "                   'change': 'NOUN', 'from': 'ADP', 'big': 'ADJ', 'business': 'NOUN', 'groups': 'NOUN',\n",
    "                   'and': 'CCONJ', 'investors': 'NOUN', 'Surveys': 'NOUN', 'continue': 'VERB', 'to': 'PART',\n",
    "                   'show': 'VERB', 'that': 'SCONJ', 'black': 'ADJ', 'Asian': 'ADJ', 'or': 'CCONJ',\n",
    "                   'minority': 'NOUN', 'ethnic': 'ADJ', 'people': 'NOUN', 'are': 'AUX',\n",
    "                   'under-represented': 'VERB', 'in': 'ADP', 'senior': 'ADJ', 'positions': 'NOUN', \n",
    "                   'But': 'CCONJ', 'some': 'PRON', 'succeed': 'VERB', 'and': 'CCONJ', 'then': 'ADV',\n",
    "                   'turn': 'VERB', 'their': 'PRON', 'drive': 'VERB', 'and': 'CCONJ', 'passion': 'NOUN', \n",
    "                   'to': 'ADP', 'helping': 'NOUN', 'others': 'PRON', 'The': 'DT', 'BBC': 'NOUN',\n",
    "                   'has': 'AUX', 'spoken': 'VERB', 'to': 'ADP', 'four': 'NUM', 'of': 'ADP', 'them': 'PRON',\n",
    "                   'But': 'CCONJ', 'after': 'ADP', 'she': 'PRON', 'left': 'VERB', 'she': 'PRON',\n",
    "                   'realised': 'VERB', 'she': 'PRON', 'had': 'AUX', 'been': 'AUX', 'altering': 'VERB',\n",
    "                   'her': 'PRON', 'personality': 'NOUN', 'to': 'PART', 'fit': 'VERB', 'in': 'ADP', \n",
    "                   'But': 'CCONJ', 'I': 'PRON', 'made': 'VERB', 'an': 'DET', 'assumption': 'VERB', \n",
    "                   'I': 'PRON', 'should': 'AUX', 'be': 'VERB', 'just': 'ADV', 'like': 'SCONJ', 'them': 'PRON',\n",
    "                   'If': 'SCONJ', 'you': 'PRON', '’re': 'VERB', 'black': 'ADJ', 'generally': 'ADV',\n",
    "                   'the': 'DET', 'experience': 'NOUN', 'is': 'VERB', 'worse': 'ADJ', 'she': 'PRON',\n",
    "                   'says': 'VERB'}\n",
    "    print('Оценка разбора SpaCy')\n",
    "    p = accuracy_spacy(parsed_text_eng, r)\n",
    "    print('########################')\n",
    "    print('Оценка разбора Flair')\n",
    "    a = accuracy_flair(parsed_text_eng, t)\n",
    "    print('########################')\n",
    "    print('Оценка разбора NLTK')\n",
    "    s = accuracy_nltk(parsed_text_eng, parsed_nltk)\n",
    "    print('########################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка разбора Pymorphy2\n",
      "Accuracy: 0.8352\n",
      "########################\n",
      "Оценка разбора Mystem\n",
      "Accuracy: 0.9011\n",
      "########################\n",
      "Оценка разбора Natasha\n",
      "Accuracy: 0.7363\n",
      "########################\n",
      "Оценка разбора SpaCy\n",
      "Accuracy: 0.8125\n",
      "########################\n",
      "Оценка разбора Flair\n",
      "Accuracy: 0.8125\n",
      "########################\n",
      "Оценка разбора NLTK\n",
      "Accuracy: 0.7500\n",
      "########################\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выделение синтаксических групп с помощью mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем выделять следующие три вида синтаксических групп:\n",
    "1) наречие + глагол\n",
    "2) глагол + наречие\n",
    "3) прилагательное + существительное"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решила взять именно эти синтаксические группы, потому что у меня были отзывы на бары, то есть там очень много таких групп как \"хорошо готовят\", \"кормят вкусно\", \"приветливый персонал\" и так далее. Кажется, для отзывов в целом, это очень частотные синтаксические группы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sintactic_groups(text):\n",
    "    words = []\n",
    "    pos = []\n",
    "    groups = []\n",
    "    ana = m.analyze(text)\n",
    "    for a in ana:\n",
    "        if 'analysis' in a:\n",
    "            gr = word['analysis'][0]['gr']\n",
    "            pos_tag = gr.split('=')[0].split(',')[0]\n",
    "            word = a['text']\n",
    "            words.append(word)\n",
    "            pos.append(pos_tag)\n",
    "    for i in range(len(pos)):\n",
    "        if pos[i] == 'ADVPRO' and pos[i+1] == 'V':\n",
    "            group = words[i] + ' ' + words[i+1]\n",
    "            groups.append(group)\n",
    "        elif pos[i] == 'V' and pos[i+1] == 'ADVPRO':\n",
    "            group = words[i] + ' ' + words[i+1]\n",
    "            groups.append(group)\n",
    "        elif pos[i] == 'A' and pos[i+1] == 'S':\n",
    "            group = words[i] + ' ' + words[i+1]\n",
    "            groups.append(group)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я вставила эту функцию в дз 1 и залила на гитхаб тетрадку \"homework_1_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
