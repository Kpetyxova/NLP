{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем 30 положительных отзывов о баре \"Ровесник\" с яндекс карт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_positive_reviews():\n",
    "    result = requests.get('https://yandex.ru/maps/org/rovesnik/168523045237/reviews/?ll=37.605949%2C55.762399&z=15')\n",
    "    html = result.text\n",
    "    positive_reviews = []\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    review = soup.find_all('div', {'class': 'reviews-view__reviews'})\n",
    "    for rev in soup.find_all('div', {'class': 'business-review-view'}):\n",
    "        counter = 0\n",
    "        text = rev.find('div', {'class': 'business-review-view__body-text _collapsed'})\n",
    "        t = text.get_text()\n",
    "        for stars in rev.find_all('span', {'class': 'business-rating-badge-view__star _size_m'}):\n",
    "            counter += 1\n",
    "            if counter == 5 and len(positive_reviews) < 30:\n",
    "                positive_reviews.append(t) \n",
    "    return positive_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в яндекс картах, чтобы открыть больше отзывов, нужно нажать кнопку \"показать еще\" (то есть я не могу так поменять ссылку, чтобы увидеть больше отзывов), то я просто пройдусь одной функцией по трем разным барам, чтобы набрать 30 отрицательных отзывов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_negative_reviews(negative_reviews, link):\n",
    "    result = requests.get(link)\n",
    "    html = result.text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    review = soup.find_all('div', {'class': 'reviews-view__reviews'})\n",
    "    for rev in soup.find_all('div', {'class': 'business-review-view'}):\n",
    "        counter = 0\n",
    "        text = rev.find('div', {'class': 'business-review-view__body-text _collapsed'})\n",
    "        t = text.get_text()\n",
    "        for stars in rev.find_all('span', {'class': 'business-rating-badge-view__star _empty _size_m'}):\n",
    "            counter += 1\n",
    "            if counter == 3 and len(negative_reviews) < 30:\n",
    "                negative_reviews.append(t)\n",
    "    return negative_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отчистим положительные отзывы от пунктуации, приведем слова к нижнему регистру, токенизируем каждый отзыв, приведем каждый токен к нормальной форме и запишем в список. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_positive_reviews(positive_reviews):\n",
    "    tokenized_positive = []\n",
    "    for text in positive_reviews:\n",
    "        words = re.sub(r'[^\\w^\\s\\']', '', text)\n",
    "        words = words.lower()\n",
    "        tokenized_text = word_tokenize(words)\n",
    "        for word in tokenized_text:\n",
    "            ana = morph.parse(word)\n",
    "            ana = ana[0]\n",
    "            lemma = ana.normal_form\n",
    "            tokenized_positive.append(lemma)\n",
    "    return tokenized_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция из дз 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_sintactic_groups(positive_reviews, tokenized_positive):\n",
    "    words = []\n",
    "    pos = []\n",
    "    for text in positive_reviews:\n",
    "        ana = m.analyze(text)\n",
    "        for a in ana:\n",
    "            if ('analysis' in a) and (a['analysis'] != []):\n",
    "                gr = a['analysis'][0]['gr']\n",
    "                pos_tag = gr.split('=')[0].split(',')[0]\n",
    "                word = a['text']\n",
    "                words.append(word)\n",
    "                pos.append(pos_tag)\n",
    "        for i in range(1, len(pos)):\n",
    "            if pos[i] == 'V' and pos[i-1] == 'ADVPRO':\n",
    "                group = words[i] + ' ' + words[i-1]\n",
    "                tokenized_positive.append(group)\n",
    "            elif pos[i] == 'ADVPRO' and pos[i-1] == 'V':\n",
    "                group = words[i] + ' ' + words[i-1]\n",
    "                tokenized_positive.append(group)\n",
    "            elif pos[i] == 'S' and pos[i-1] == 'A':\n",
    "                group = words[i] + ' ' + words[i-1]\n",
    "                tokenized_positive.append(group)\n",
    "    return tokenized_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь сделаем все то же самое, только для отрицательных отзывов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_negative_reviews(negative_reviews):\n",
    "    tokenized_negative = []\n",
    "    for text in negative_reviews:\n",
    "        words = re.sub(r'[^\\w^\\s\\']', '', text)\n",
    "        words = words.lower()\n",
    "        tokenized_text = word_tokenize(words)\n",
    "        for word in tokenized_text:\n",
    "            ana = morph.parse(word)\n",
    "            ana = ana[0]\n",
    "            lemma = ana.normal_form\n",
    "            tokenized_negative.append(lemma)\n",
    "    return tokenized_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция из дз 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sintactic_groups(negative_reviews, tokenized_negative):\n",
    "    words = []\n",
    "    pos = []\n",
    "    for text in negative_reviews:\n",
    "        ana = m.analyze(text)\n",
    "        for a in ana:\n",
    "            if ('analysis' in a) and (a['analysis'] != []):\n",
    "                gr = a['analysis'][0]['gr']\n",
    "                pos_tag = gr.split('=')[0].split(',')[0]\n",
    "                word = a['text']\n",
    "                words.append(word)\n",
    "                pos.append(pos_tag)\n",
    "        for i in range(1, len(pos)):\n",
    "            if pos[i] == 'V' and pos[i-1] == 'ADVPRO':\n",
    "                group = words[i] + ' ' + words[i-1]\n",
    "                tokenized_negative.append(group)\n",
    "            elif pos[i] == 'ADVPRO' and pos[i-1] == 'V':\n",
    "                group = words[i] + ' ' + words[i-1]\n",
    "                tokenized_negative.append(group)\n",
    "            elif pos[i] == 'S' and pos[i-1] == 'A':\n",
    "                group = words[i] + ' ' + words[i-1]\n",
    "                tokenized_negative.append(group)\n",
    "    return tokenized_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим два словаря уникальных слов (положительных и отрицательных), где ключомами является слова, а значениями - то, сколько раз они встретились. \n",
    "Затем создадим два списка, для положительных и отрицательных слов, встретившихся больше двух раз. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(tokenized_positive, tokenized_negative):\n",
    "    positive_words = []\n",
    "    positive = []\n",
    "    for x in tokenized_positive:\n",
    "        if x not in tokenized_negative:\n",
    "            positive_words.append(x)\n",
    "    counter = collections.Counter(positive_words)\n",
    "    counter = dict(counter)\n",
    "    for key in counter:\n",
    "        if counter[key] != 1 and counter[key] != 2:\n",
    "            positive.append(key)\n",
    "    negative_words = []\n",
    "    negative = []\n",
    "    for x in tokenized_negative:\n",
    "        if x not in tokenized_positive:\n",
    "            negative_words.append(x)\n",
    "    counter_2 = collections.Counter(negative_words)\n",
    "    counter_2 = dict(counter_2)\n",
    "    for key in counter_2:\n",
    "        if counter_2[key] != 1 and counter_2[key] != 2:\n",
    "            negative.append(key)\n",
    "    return positive, negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая функция на вход принимает текст, из которого создает список нормальных форм. Затем она проходится по каждому слову и считает, сколько из них встречаются в списках с положительными и отрицательными словами, и возвращает ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(positive, negative, text):\n",
    "    tokenized_review = []\n",
    "    words = re.sub(r'[^\\w^\\s\\']', '', text)\n",
    "    words = words.lower()\n",
    "    tokenized_text = word_tokenize(words)\n",
    "    for word in tokenized_text:\n",
    "        ana = morph.parse(word)\n",
    "        ana = ana[0]\n",
    "        lemma = ana.normal_form\n",
    "        tokenized_review.append(lemma)\n",
    "    counter_pos = 0\n",
    "    counter_neg = 0\n",
    "    for lemma in tokenized_review:\n",
    "        if lemma in positive:\n",
    "            counter_pos += 1\n",
    "        if lemma in negative:\n",
    "            counter_neg += 1\n",
    "    if counter_pos > counter_neg:\n",
    "        return 'pos'\n",
    "    else:\n",
    "        return 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /anaconda3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /anaconda3/lib/python3.7/site-packages (from sklearn) (0.21.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.16.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем, с какой точностью наша программа определяет тональность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_positive():\n",
    "    positive_test = []\n",
    "    result = requests.get('https://yandex.ru/maps/org/ryumochnaya_svoboda/147745010375/reviews/?ll=37.637587%2C55.762414&z=15')\n",
    "    html = result.text\n",
    "    positive_reviews = []\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    review = soup.find_all('div', {'class': 'reviews-view__reviews'})\n",
    "    for rev in soup.find_all('div', {'class': 'business-review-view'}):\n",
    "        counter = 0\n",
    "        text = rev.find('div', {'class': 'business-review-view__body-text _collapsed'})\n",
    "        t = text.get_text()\n",
    "        for stars in rev.find_all('span', {'class': 'business-rating-badge-view__star _size_m'}):\n",
    "            counter += 1\n",
    "            if counter == 5 and len(positive_reviews) < 30:\n",
    "                positive_test.append(t) \n",
    "    return positive_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_negative():\n",
    "    negative_test = []\n",
    "    result = requests.get('https://yandex.ru/maps/213/moscow/?display-text=KillFish&ll=37.648735%2C55.759693&mode=search&oid=1902978412&ol=biz&sll=37.631343%2C55.742509&sspn=0.008154%2C0.007469&text=%7B%22text%22%3A%22KillFish%22%2C%22what%22%3A%5B%7B%22attr_name%22%3A%22chain_id%22%2C%22attr_values%22%3A%5B%222778132496%22%5D%7D%5D%7D&z=13')\n",
    "    html = result.text\n",
    "    positive_reviews = []\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    review = soup.find_all('div', {'class': 'reviews-view__reviews'})\n",
    "    for rev in soup.find_all('div', {'class': 'business-review-view'}):\n",
    "        counter = 0\n",
    "        text = rev.find('div', {'class': 'business-review-view__body-text _collapsed'})\n",
    "        t = text.get_text()\n",
    "        for stars in rev.find_all('span', {'class': 'business-rating-badge-view__star _empty _size_m'}):\n",
    "            counter += 1\n",
    "            if counter == 3 and len(negative_reviews) < 30:\n",
    "                negative_test.append(t)\n",
    "    return negative_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_detect(positive, negative):\n",
    "    results = []\n",
    "    gold = []\n",
    "    for text in test_positive():\n",
    "        predicted = detect(positive, negative, text)\n",
    "        results.append(predicted)\n",
    "        gold.append('pos')\n",
    "    for text in test_negative():\n",
    "        predicted = detect(positive, negative, text)\n",
    "        results.append(predicted)\n",
    "        gold.append('neg')\n",
    "    #print(results) \n",
    "    #print(gold)\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    negative_reviews = []\n",
    "    link_1 = 'https://yandex.ru/maps/org/rovesnik/168523045237/reviews/?ll=37.605949%2C55.762399&z=15'\n",
    "    link_2 = 'https://yandex.ru/maps/org/profsoyuz_barnoye_obyedineniye/133933857803/reviews/?ll=37.600092%2C55.782333&z=17'\n",
    "    link_3 = 'https://yandex.ru/maps/org/zinziver/27339938644/reviews/?ll=37.645473%2C55.758883&z=14'\n",
    "    a = find_positive_reviews()\n",
    "    b = find_negative_reviews(negative_reviews, link_1)\n",
    "    c = find_negative_reviews(b, link_2)\n",
    "    d = find_negative_reviews(c, link_3)\n",
    "    q = tokenize_positive_reviews(a)\n",
    "    m = positive_sintactic_groups(a, q)\n",
    "    w = tokenize_negative_reviews(d)\n",
    "    n = negative_sintactic_groups(d, w)\n",
    "    e, r = clean_words(m, n)\n",
    "    t = test_detect(e, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как мы видим, по сравнению с прошлой тетрадкой точность стала выше  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7059\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Понятно, что нужно увеличить количество данных;\n",
    "2) Можно также из отзывов поубирать стоп слова, чтобы очистить множества от слов, не несущих эмоциональную окраску;\n",
    "3) Можно добавить в алгоритм векторайзер, чтобы потом сравнивать ветора с помощью разных метрик;\n",
    "4) Или можно использовать word2vec, чтобы искать семантически близкие слова;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
