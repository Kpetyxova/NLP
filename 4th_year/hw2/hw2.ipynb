{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjnh8nVxExRe"
      },
      "source": [
        "Скачиваем файлы (я работаю с датасетом Luxury_Beauty)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RavdVV1zGFAP",
        "outputId": "2a8a9ab2-ea30-4862-bf60-df019f9a062c"
      },
      "source": [
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Luxury_Beauty.json.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-05 09:40:50--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Luxury_Beauty.json.gz\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 73193215 (70M) [application/octet-stream]\n",
            "Saving to: ‘Luxury_Beauty.json.gz’\n",
            "\n",
            "Luxury_Beauty.json. 100%[===================>]  69.80M  68.4MB/s    in 1.0s    \n",
            "\n",
            "2021-12-05 09:40:51 (68.4 MB/s) - ‘Luxury_Beauty.json.gz’ saved [73193215/73193215]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUeRXOM0Bh9o"
      },
      "source": [
        "!gzip -d /content/Luxury_Beauty.json.gz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiAgqkfrE5MF"
      },
      "source": [
        "Импортируем все необходимое"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR7Yd4m2cvz5",
        "outputId": "c9edd71a-3a34-4aff-b384-f0438c23f50a"
      },
      "source": [
        "!pip install ufal.udpipe"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ufal.udpipe\n",
            "  Downloading ufal.udpipe-1.2.0.3.tar.gz (304 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 112 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 153 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 163 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 174 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 184 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 194 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 204 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 215 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 225 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 235 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 245 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 266 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 276 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 286 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 296 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 304 kB 6.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ufal.udpipe\n",
            "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp37-cp37m-linux_x86_64.whl size=5626630 sha256=c296708275781585957199096919019086a39a0ceee82c8eda8dc4be26efe68a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/b5/8e/3da091629a21ce2d10bf90759d0cb034ba10a5cf7a01e83d64\n",
            "Successfully built ufal.udpipe\n",
            "Installing collected packages: ufal.udpipe\n",
            "Successfully installed ufal.udpipe-1.2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksvn-JIPx4vz",
        "outputId": "73ea27da-999b-4096-c056-3cdea8474d52"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 13.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdor1jDeCn1X",
        "outputId": "4a1a576b-d1cd-41e6-e691-331b4458a8ac"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import ufal.udpipe\n",
        "import re\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import spacy\n",
        "from nltk.collocations import *\n",
        "spacy_nlp = spacy.load('en_core_web_sm')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "sw = stopwords.words('english')\n",
        "random.seed(42)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wydR1eb8DeeM"
      },
      "source": [
        "data = []\n",
        "for line in open('/content/Luxury_Beauty.json', 'r'):\n",
        "    data.append(json.loads(line))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0qehSoulkgy"
      },
      "source": [
        "random.shuffle(data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQFeMO4Wl6L5"
      },
      "source": [
        "data = data[:10000]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_kTUdFOZqSL"
      },
      "source": [
        "df = pd.DataFrame(data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "oFkXLYTYZwSB",
        "outputId": "dbc600a9-b8b2-4d08-a841-89752026faf7"
      },
      "source": [
        "df"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>style</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>vote</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>True</td>\n",
              "      <td>08 18, 2015</td>\n",
              "      <td>A15BBWMRP1XF0</td>\n",
              "      <td>B000BIGOY2</td>\n",
              "      <td>{'Color:': ' Light'}</td>\n",
              "      <td>Wendy</td>\n",
              "      <td>The product was average.  I am only giving it ...</td>\n",
              "      <td>theBalm TimeBalm Concealer</td>\n",
              "      <td>1439856000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>03 8, 2015</td>\n",
              "      <td>A14LYQMHYIX6F3</td>\n",
              "      <td>B00983KT42</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BlondeOnTour</td>\n",
              "      <td>Saw improvement in skin in about 30 days, used...</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1425772800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 1, 2013</td>\n",
              "      <td>A2DOPOYFI1EVYO</td>\n",
              "      <td>B0006ODQII</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Auntie</td>\n",
              "      <td>I have been using this product for 20 years. I...</td>\n",
              "      <td>Love it</td>\n",
              "      <td>1383264000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>09 13, 2017</td>\n",
              "      <td>ATAVB4R6QZPYF</td>\n",
              "      <td>B00UGLH286</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HunterTHL</td>\n",
              "      <td>Great product that requires small amount to se...</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1505260800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>04 3, 2012</td>\n",
              "      <td>A1U3YH99KV7UPU</td>\n",
              "      <td>B000J5A2K4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gogolatinboy</td>\n",
              "      <td>I love this deodorant...not only smells really...</td>\n",
              "      <td>a KEEPER</td>\n",
              "      <td>1333411200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 23, 2014</td>\n",
              "      <td>A30U5CXFOJ7DQ5</td>\n",
              "      <td>B00CA0BMSW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Obaida Batal</td>\n",
              "      <td>fits great , work great</td>\n",
              "      <td>fits great, work great</td>\n",
              "      <td>1416700800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>10 17, 2017</td>\n",
              "      <td>A1VOVGNX054PQC</td>\n",
              "      <td>B00172JYKW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Elizabeth von Eschenbach</td>\n",
              "      <td>This stuff is amazing!!  Leaves my skin glowin...</td>\n",
              "      <td>Amazing!!</td>\n",
              "      <td>1508198400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>08 18, 2010</td>\n",
              "      <td>A17F9KN0FLRLLJ</td>\n",
              "      <td>B000248HLI</td>\n",
              "      <td>{'Format:': ' Health and Beauty'}</td>\n",
              "      <td>Mister Casual</td>\n",
              "      <td>My order was shipped on the 17th and I receive...</td>\n",
              "      <td>Excellent!!</td>\n",
              "      <td>1282089600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>12 3, 2012</td>\n",
              "      <td>A1SN1YD8KNILJG</td>\n",
              "      <td>B0016191HU</td>\n",
              "      <td>{'Size:': ' 8.45 fl. oz.'}</td>\n",
              "      <td>BAR8888</td>\n",
              "      <td>I have long, thin hair that is dry from highli...</td>\n",
              "      <td>Great for dry hair!</td>\n",
              "      <td>1354492800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 1, 2013</td>\n",
              "      <td>AS9FKELRT3NOD</td>\n",
              "      <td>B000YBNL2Y</td>\n",
              "      <td>{'Color:': ' Natural'}</td>\n",
              "      <td>annette galles</td>\n",
              "      <td>It is a fantastic product. I am happy with it ...</td>\n",
              "      <td>Love the product!</td>\n",
              "      <td>1383264000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      overall  verified   reviewTime  ... unixReviewTime vote image\n",
              "0         2.0      True  08 18, 2015  ...     1439856000  NaN   NaN\n",
              "1         5.0      True   03 8, 2015  ...     1425772800  NaN   NaN\n",
              "2         5.0      True   11 1, 2013  ...     1383264000  NaN   NaN\n",
              "3         5.0      True  09 13, 2017  ...     1505260800  NaN   NaN\n",
              "4         5.0      True   04 3, 2012  ...     1333411200  NaN   NaN\n",
              "...       ...       ...          ...  ...            ...  ...   ...\n",
              "9995      5.0      True  11 23, 2014  ...     1416700800  NaN   NaN\n",
              "9996      5.0      True  10 17, 2017  ...     1508198400  NaN   NaN\n",
              "9997      5.0      True  08 18, 2010  ...     1282089600  NaN   NaN\n",
              "9998      5.0      True   12 3, 2012  ...     1354492800  NaN   NaN\n",
              "9999      5.0      True   11 1, 2013  ...     1383264000  NaN   NaN\n",
              "\n",
              "[10000 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJOVa9pdHM6q"
      },
      "source": [
        "### 3 способа найти упоминания товаров в отзывах:\n",
        "* можно было бы написать парсер, который берет слово/нграмму и идет в викидату посмотреть, не относится ли это слово/нграмма к нужной нам группе слов (можно было бы взять \"personal care products\": Q3246832, и \"cosmetics\": Q131207)\n",
        "* можно составить список глаголов, таких как [\"buy\", \"use\", \"love\"]. Затем распарсить предложения с помощью какого-нибудь UDPipe, и для форм выбранных нами глаголов извлекать их прямые объекты\n",
        "* можно извлечь все конструкции вида ADJ+NP, прогнать их через какой-нибудь классификатор полярности и сохранить те именные группы, которые употребляются с положительными или негативными прилагательными\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKKMiownXDY4"
      },
      "source": [
        "Я попробую реализовать второй вариант."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wohJsbC3FHxZ"
      },
      "source": [
        "# предлагаю в данном дз поработать со следующими глаголами:\n",
        "verbs = [\"buy\", \"use\", \"love\", \"try\", \"like\", \"discover\", \"need\", \"purchase\", \"hate\"] # для этих глаголов можно брать прямые объекты\n",
        "verbs_2 = [\"work\", \"break\"] # для этих глаголов можно брать субъекты"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AcD9inFZb25"
      },
      "source": [
        "review_texts = list(df.reviewText)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hATc7bkvcUv-",
        "outputId": "4d4465b9-6fcd-4f78-b081-fac8d167b47e"
      },
      "source": [
        "!wget https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/english-gum-ud-2.5-191206.udpipe?sequence=31&isAllowed=y"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-05 09:47:06--  https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/english-gum-ud-2.5-191206.udpipe?sequence=31\n",
            "Resolving lindat.mff.cuni.cz (lindat.mff.cuni.cz)... 195.113.20.140\n",
            "Connecting to lindat.mff.cuni.cz (lindat.mff.cuni.cz)|195.113.20.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8880020 (8.5M) [application/octet-stream]\n",
            "Saving to: ‘english-gum-ud-2.5-191206.udpipe?sequence=31’\n",
            "\n",
            "english-gum-ud-2.5- 100%[===================>]   8.47M  6.47MB/s    in 1.3s    \n",
            "\n",
            "2021-12-05 09:47:09 (6.47 MB/s) - ‘english-gum-ud-2.5-191206.udpipe?sequence=31’ saved [8880020/8880020]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cPvLN-waRD6"
      },
      "source": [
        "model = ufal.udpipe.Model.load('/content/english-gum-ud-2.5-191206.udpipe?sequence=31')\n",
        "tokenizer = model.newTokenizer(model.DEFAULT)\n",
        "conlluOutput = ufal.udpipe.OutputFormat.newOutputFormat(\"conllu\")\n",
        "sentence = ufal.udpipe.Sentence()\n",
        "error = ufal.udpipe.ProcessingError()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ27qCccciOn"
      },
      "source": [
        "def tag(text, model):\n",
        "    tokenizer.setText(text)\n",
        "    tokenizer.nextSentence(sentence, error)\n",
        "    model.tag(sentence, model.DEFAULT)\n",
        "    model.parse(sentence, model.DEFAULT)\n",
        "    return conlluOutput.writeSentence(sentence)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti5zszeOfCcy",
        "outputId": "49b08ad3-ac2d-4162-c455-9b6bca250358"
      },
      "source": [
        "reviews_parsed = []\n",
        "review_id_for_sentence = []\n",
        "for text in tqdm(review_texts):\n",
        "  rev_parsed = []\n",
        "  index_ex = review_texts.index(text)\n",
        "  if type(text) == str:\n",
        "    slist = sent_tokenize(text)\n",
        "    for s in slist:\n",
        "        s = tag(s, model)\n",
        "        rev_parsed.append(s)\n",
        "        review_id_for_sentence.append(index_ex)\n",
        "\n",
        "  reviews_parsed.append(rev_parsed)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [06:42<00:00, 24.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c4yUjD4rZ_F",
        "outputId": "86fba249-bb2f-4465-8a97-7c3fb0d90237"
      },
      "source": [
        "print(reviews_parsed[0][0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# newdoc\n",
            "# newpar\n",
            "# sent_id = 1\n",
            "# text = The product was average.\n",
            "1\tThe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t2\tdet\t_\t_\n",
            "2\tproduct\tproduct\tNOUN\tNN\tNumber=Sing\t4\tnsubj\t_\t_\n",
            "3\twas\tbe\tAUX\tVBD\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\t4\tcop\t_\t_\n",
            "4\taverage\taverage\tADJ\tJJ\tDegree=Pos\t0\troot\t_\tSpaceAfter=No\n",
            "5\t.\t.\tPUNCT\t.\t_\t4\tpunct\t_\tSpaceAfter=No\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c8CvxqSv8EJ"
      },
      "source": [
        "df['reviews_ud'] = reviews_parsed"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83rAP0OZsFMj",
        "outputId": "2a3487fb-e826-4d66-c0bd-1281761ba32f"
      },
      "source": [
        "verbs_all = verbs + verbs_2\n",
        "sentences_all = []\n",
        "lemmatized_sentences_all = []\n",
        "sent_targets_all = []\n",
        "\n",
        "for review in tqdm(reviews_parsed):\n",
        "  sentences = []\n",
        "  lemmatized_sentences = []\n",
        "  sent_targets = []\n",
        "  sent_lemm_targets = []\n",
        "  for text in review:\n",
        "      target = ''\n",
        "      lemmas = []\n",
        "      sent = re.findall(r'\\n# text = (.*?)\\n1\\t', text)\n",
        "      sent = ' '.join(sent)\n",
        "      sentences.append(sent)\n",
        "      sent = re.sub(r'[^\\w^\\s\\']', '', sent)\n",
        "      sent = sent.lower()\n",
        "      doc = spacy_nlp(sent)\n",
        "      lemmatized_sent = [token.lemma_ for token in doc]\n",
        "      for token in lemmatized_sent:\n",
        "          if token in verbs_all:\n",
        "              target = token\n",
        "              \n",
        "      sent_targets.append(target)   \n",
        "      lemmatized_sentences.append(' '.join(lemmatized_sent))\n",
        "  sentences_all.append(sentences)\n",
        "  lemmatized_sentences_all.append(lemmatized_sentences)\n",
        "  sent_targets_all.append(sent_targets)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [05:25<00:00, 30.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_k0wrUzf36d"
      },
      "source": [
        "df['lemmatized_sentences'] = lemmatized_sentences_all\n",
        "df['targets'] = sent_targets_all"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zdUucxtVxv3a",
        "outputId": "629e8521-29d5-453c-8d20-c0d298c15bc1"
      },
      "source": [
        "df"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>style</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>vote</th>\n",
              "      <th>image</th>\n",
              "      <th>reviews_ud</th>\n",
              "      <th>lemmatized_sentences</th>\n",
              "      <th>targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>True</td>\n",
              "      <td>08 18, 2015</td>\n",
              "      <td>A15BBWMRP1XF0</td>\n",
              "      <td>B000BIGOY2</td>\n",
              "      <td>{'Color:': ' Light'}</td>\n",
              "      <td>Wendy</td>\n",
              "      <td>The product was average.  I am only giving it ...</td>\n",
              "      <td>theBalm TimeBalm Concealer</td>\n",
              "      <td>1439856000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# newdoc\\n# newpar\\n# sent_id = 1\\n# text = T...</td>\n",
              "      <td>[the product be average, i be only give -PRON-...</td>\n",
              "      <td>[, , use, , purchase]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>03 8, 2015</td>\n",
              "      <td>A14LYQMHYIX6F3</td>\n",
              "      <td>B00983KT42</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BlondeOnTour</td>\n",
              "      <td>Saw improvement in skin in about 30 days, used...</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1425772800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 6\\n# text = Saw improvement in sk...</td>\n",
              "      <td>[see improvement in skin in about 30 day use e...</td>\n",
              "      <td>[use]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 1, 2013</td>\n",
              "      <td>A2DOPOYFI1EVYO</td>\n",
              "      <td>B0006ODQII</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Auntie</td>\n",
              "      <td>I have been using this product for 20 years. I...</td>\n",
              "      <td>Love it</td>\n",
              "      <td>1383264000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 7\\n# text = I have been using thi...</td>\n",
              "      <td>[i have be use this product for 20 year, i be ...</td>\n",
              "      <td>[use, ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>09 13, 2017</td>\n",
              "      <td>ATAVB4R6QZPYF</td>\n",
              "      <td>B00UGLH286</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HunterTHL</td>\n",
              "      <td>Great product that requires small amount to se...</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1505260800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 9\\n# text = Great product that re...</td>\n",
              "      <td>[great product that require small amount to se...</td>\n",
              "      <td>[, ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>04 3, 2012</td>\n",
              "      <td>A1U3YH99KV7UPU</td>\n",
              "      <td>B000J5A2K4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gogolatinboy</td>\n",
              "      <td>I love this deodorant...not only smells really...</td>\n",
              "      <td>a KEEPER</td>\n",
              "      <td>1333411200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 11\\n# text = I love this deodoran...</td>\n",
              "      <td>[i love this deodorantnot only smell really go...</td>\n",
              "      <td>[love, use, ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 23, 2014</td>\n",
              "      <td>A30U5CXFOJ7DQ5</td>\n",
              "      <td>B00CA0BMSW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Obaida Batal</td>\n",
              "      <td>fits great , work great</td>\n",
              "      <td>fits great, work great</td>\n",
              "      <td>1416700800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 33890\\n# text = fits great , work...</td>\n",
              "      <td>[fit great   work great]</td>\n",
              "      <td>[work]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>10 17, 2017</td>\n",
              "      <td>A1VOVGNX054PQC</td>\n",
              "      <td>B00172JYKW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Elizabeth von Eschenbach</td>\n",
              "      <td>This stuff is amazing!!  Leaves my skin glowin...</td>\n",
              "      <td>Amazing!!</td>\n",
              "      <td>1508198400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 33891\\n# text = This stuff is ama...</td>\n",
              "      <td>[this stuff be amazing, leave -PRON- skin glow...</td>\n",
              "      <td>[, , ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>08 18, 2010</td>\n",
              "      <td>A17F9KN0FLRLLJ</td>\n",
              "      <td>B000248HLI</td>\n",
              "      <td>{'Format:': ' Health and Beauty'}</td>\n",
              "      <td>Mister Casual</td>\n",
              "      <td>My order was shipped on the 17th and I receive...</td>\n",
              "      <td>Excellent!!</td>\n",
              "      <td>1282089600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 33894\\n# text = My order was ship...</td>\n",
              "      <td>[-PRON- order be ship on the 17th and i receiv...</td>\n",
              "      <td>[, love, , ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>12 3, 2012</td>\n",
              "      <td>A1SN1YD8KNILJG</td>\n",
              "      <td>B0016191HU</td>\n",
              "      <td>{'Size:': ' 8.45 fl. oz.'}</td>\n",
              "      <td>BAR8888</td>\n",
              "      <td>I have long, thin hair that is dry from highli...</td>\n",
              "      <td>Great for dry hair!</td>\n",
              "      <td>1354492800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 33898\\n# text = I have long, thin...</td>\n",
              "      <td>[i have long thin hair that be dry from highli...</td>\n",
              "      <td>[, , ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 1, 2013</td>\n",
              "      <td>AS9FKELRT3NOD</td>\n",
              "      <td>B000YBNL2Y</td>\n",
              "      <td>{'Color:': ' Natural'}</td>\n",
              "      <td>annette galles</td>\n",
              "      <td>It is a fantastic product. I am happy with it ...</td>\n",
              "      <td>Love the product!</td>\n",
              "      <td>1383264000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 33901\\n# text = It is a fantastic...</td>\n",
              "      <td>[-PRON- be a fantastic product, i be happy wit...</td>\n",
              "      <td>[, , ]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      overall  ...                targets\n",
              "0         2.0  ...  [, , use, , purchase]\n",
              "1         5.0  ...                  [use]\n",
              "2         5.0  ...                [use, ]\n",
              "3         5.0  ...                   [, ]\n",
              "4         5.0  ...          [love, use, ]\n",
              "...       ...  ...                    ...\n",
              "9995      5.0  ...                 [work]\n",
              "9996      5.0  ...                 [, , ]\n",
              "9997      5.0  ...           [, love, , ]\n",
              "9998      5.0  ...                 [, , ]\n",
              "9999      5.0  ...                 [, , ]\n",
              "\n",
              "[10000 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow96LjS433iN"
      },
      "source": [
        "def find_arguments_obj(target_id, text):\n",
        "    list_arguments = []\n",
        "    list_syntax_roles = []\n",
        "    list_pos = []\n",
        "    list_morph_features = []\n",
        "    match_word = re.findall(r'\\n\\d*?\\t(.*?)\\t.*?\\t.*?\\t.*?\\t.*?\\t' + target_id + '\\t.*?\\t_\\t.*?\\n', text)\n",
        "    match_syntax = re.findall(r'\\n\\d*?\\t.*?\\t.*?\\t.*?\\t.*?\\t.*?\\t' + target_id + '\\t(.*?)\\t_\\t.*?\\n', text)\n",
        "    match_pos = re.findall(r'\\n\\d*?\\t.*?\\t.*?\\t(.*?)\\t.*?\\t.*?\\t' + target_id + '\\t.*?\\t_\\t.*?\\n', text)\n",
        "    match_morph = re.findall(r'\\n\\d*?\\t.*?\\t.*?\\t.*?\\t.*?\\t(.*?)\\t' + target_id + '\\t.*?\\t_\\t.*?\\n', text)\n",
        "    for i in range(len(match_word)):\n",
        "        if (match_syntax[i] == 'obj') and (match_pos[i] != 'PRON'):\n",
        "            list_arguments.append(match_word[i])\n",
        "            list_syntax_roles.append(match_syntax[i])\n",
        "            list_pos.append(match_pos[i])\n",
        "            list_morph_features.append(match_morph[i])\n",
        "    \n",
        "    return list_arguments, list_syntax_roles, list_pos, list_morph_features\n",
        "\n",
        "\n",
        "def find_arguments_subj(target_id, text):\n",
        "    list_arguments = []\n",
        "    list_syntax_roles = []\n",
        "    list_pos = []\n",
        "    list_morph_features = []\n",
        "    match_word = re.findall(r'\\n\\d*?\\t(.*?)\\t.*?\\t.*?\\t.*?\\t.*?\\t' + target_id + '\\t.*?\\t_\\t.*?\\n', text)\n",
        "    match_syntax = re.findall(r'\\n\\d*?\\t.*?\\t.*?\\t.*?\\t.*?\\t.*?\\t' + target_id + '\\t(.*?)\\t_\\t.*?\\n', text)\n",
        "    match_pos = re.findall(r'\\n\\d*?\\t.*?\\t.*?\\t(.*?)\\t.*?\\t.*?\\t' + target_id + '\\t.*?\\t_\\t.*?\\n', text)\n",
        "    match_morph = re.findall(r'\\n\\d*?\\t.*?\\t.*?\\t.*?\\t.*?\\t(.*?)\\t' + target_id + '\\t.*?\\t_\\t.*?\\n', text)\n",
        "    for i in range(len(match_word)):\n",
        "        if (match_syntax[i] == 'nsubj') and (match_pos[i] != 'PRON'):\n",
        "            list_arguments.append(match_word[i])\n",
        "            list_syntax_roles.append(match_syntax[i])\n",
        "            list_pos.append(match_pos[i])\n",
        "            list_morph_features.append(match_morph[i])\n",
        "\n",
        "    return list_arguments, list_syntax_roles, list_pos, list_morph_features"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TZSVszVDmwK"
      },
      "source": [
        "def lemmatize(text): \n",
        "    doc = spacy_nlp(text)\n",
        "    return [token.lemma_ for token in doc][0]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWEQkneM2SJH",
        "outputId": "1f4903b1-9417-4781-b2fd-7ceba5a2ba1d"
      },
      "source": [
        "targets = list(df.targets)\n",
        "parsed_sentences = list(df.reviews_ud)\n",
        "list_all_arguments = []\n",
        "list_all_syntax_roles = []\n",
        "list_all_pos = []\n",
        "list_all_morph_features = []\n",
        "for i in tqdm(range(len(targets))):\n",
        "  args = []\n",
        "  syn = []\n",
        "  pos = []\n",
        "  morph = []\n",
        "  for y in range(len(targets[i])):\n",
        "    if targets[i][y] != '':\n",
        "      text_lower = parsed_sentences[i][y].lower()\n",
        "      match = re.findall(r'\\n(\\d*?)\\t.*?\\t' + targets[i][y], text_lower)\n",
        "      if match:\n",
        "        target_id = match[0]\n",
        "        if (lemmatize(targets[i][y].lower()) in verbs):\n",
        "          list_arguments, list_syntax_roles, list_pos, list_morph_features = find_arguments_obj(target_id, parsed_sentences[i][y])\n",
        "        elif (lemmatize(targets[i][y].lower()) in verbs_2):\n",
        "          list_arguments, list_syntax_roles, list_pos, list_morph_features = find_arguments_subj(target_id, parsed_sentences[i][y])\n",
        "\n",
        "      args = args + list_arguments\n",
        "      syn = syn + list_syntax_roles\n",
        "      pos = pos + list_pos\n",
        "      morph = morph + list_morph_features\n",
        "\n",
        "  list_all_arguments.append(args)\n",
        "  list_all_syntax_roles.append(syn)\n",
        "  list_all_pos.append(pos)\n",
        "  list_all_morph_features.append(morph)\n",
        "\n",
        "\n",
        "df['NE'] = list_all_arguments\n",
        "df['synt_roles'] = list_all_syntax_roles\n",
        "df['POS'] = list_all_pos\n",
        "df['morph_features'] = list_all_morph_features"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [02:12<00:00, 75.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yfHKcq108jby",
        "outputId": "562ae12b-767d-42ed-f990-b4c5d4216a2f"
      },
      "source": [
        " df"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>style</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>vote</th>\n",
              "      <th>image</th>\n",
              "      <th>reviews_ud</th>\n",
              "      <th>lemmatized_sentences</th>\n",
              "      <th>targets</th>\n",
              "      <th>NE</th>\n",
              "      <th>synt_roles</th>\n",
              "      <th>POS</th>\n",
              "      <th>morph_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>True</td>\n",
              "      <td>08 18, 2015</td>\n",
              "      <td>A15BBWMRP1XF0</td>\n",
              "      <td>B000BIGOY2</td>\n",
              "      <td>{'Color:': ' Light'}</td>\n",
              "      <td>Wendy</td>\n",
              "      <td>The product was average.  I am only giving it ...</td>\n",
              "      <td>theBalm TimeBalm Concealer</td>\n",
              "      <td>1439856000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# newdoc\\n# newpar\\n# sent_id = 1\\n# text = T...</td>\n",
              "      <td>[the product be average, i be only give -PRON-...</td>\n",
              "      <td>[, , use, , purchase]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>03 8, 2015</td>\n",
              "      <td>A14LYQMHYIX6F3</td>\n",
              "      <td>B00983KT42</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BlondeOnTour</td>\n",
              "      <td>Saw improvement in skin in about 30 days, used...</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1425772800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 6\\n# text = Saw improvement in sk...</td>\n",
              "      <td>[see improvement in skin in about 30 day use e...</td>\n",
              "      <td>[use]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 1, 2013</td>\n",
              "      <td>A2DOPOYFI1EVYO</td>\n",
              "      <td>B0006ODQII</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Auntie</td>\n",
              "      <td>I have been using this product for 20 years. I...</td>\n",
              "      <td>Love it</td>\n",
              "      <td>1383264000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 7\\n# text = I have been using thi...</td>\n",
              "      <td>[i have be use this product for 20 year, i be ...</td>\n",
              "      <td>[use, ]</td>\n",
              "      <td>[product]</td>\n",
              "      <td>[obj]</td>\n",
              "      <td>[NOUN]</td>\n",
              "      <td>[Number=Sing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>09 13, 2017</td>\n",
              "      <td>ATAVB4R6QZPYF</td>\n",
              "      <td>B00UGLH286</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HunterTHL</td>\n",
              "      <td>Great product that requires small amount to se...</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1505260800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 9\\n# text = Great product that re...</td>\n",
              "      <td>[great product that require small amount to se...</td>\n",
              "      <td>[, ]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>04 3, 2012</td>\n",
              "      <td>A1U3YH99KV7UPU</td>\n",
              "      <td>B000J5A2K4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gogolatinboy</td>\n",
              "      <td>I love this deodorant...not only smells really...</td>\n",
              "      <td>a KEEPER</td>\n",
              "      <td>1333411200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 11\\n# text = I love this deodoran...</td>\n",
              "      <td>[i love this deodorantnot only smell really go...</td>\n",
              "      <td>[love, use, ]</td>\n",
              "      <td>[deodorant...not]</td>\n",
              "      <td>[obj]</td>\n",
              "      <td>[NOUN]</td>\n",
              "      <td>[Number=Sing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 23, 2014</td>\n",
              "      <td>A30U5CXFOJ7DQ5</td>\n",
              "      <td>B00CA0BMSW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Obaida Batal</td>\n",
              "      <td>fits great , work great</td>\n",
              "      <td>fits great, work great</td>\n",
              "      <td>1416700800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 33890\\n# text = fits great , work...</td>\n",
              "      <td>[fit great   work great]</td>\n",
              "      <td>[work]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>10 17, 2017</td>\n",
              "      <td>A1VOVGNX054PQC</td>\n",
              "      <td>B00172JYKW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Elizabeth von Eschenbach</td>\n",
              "      <td>This stuff is amazing!!  Leaves my skin glowin...</td>\n",
              "      <td>Amazing!!</td>\n",
              "      <td>1508198400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 33891\\n# text = This stuff is ama...</td>\n",
              "      <td>[this stuff be amazing, leave -PRON- skin glow...</td>\n",
              "      <td>[, , ]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>08 18, 2010</td>\n",
              "      <td>A17F9KN0FLRLLJ</td>\n",
              "      <td>B000248HLI</td>\n",
              "      <td>{'Format:': ' Health and Beauty'}</td>\n",
              "      <td>Mister Casual</td>\n",
              "      <td>My order was shipped on the 17th and I receive...</td>\n",
              "      <td>Excellent!!</td>\n",
              "      <td>1282089600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 33894\\n# text = My order was ship...</td>\n",
              "      <td>[-PRON- order be ship on the 17th and i receiv...</td>\n",
              "      <td>[, love, , ]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>12 3, 2012</td>\n",
              "      <td>A1SN1YD8KNILJG</td>\n",
              "      <td>B0016191HU</td>\n",
              "      <td>{'Size:': ' 8.45 fl. oz.'}</td>\n",
              "      <td>BAR8888</td>\n",
              "      <td>I have long, thin hair that is dry from highli...</td>\n",
              "      <td>Great for dry hair!</td>\n",
              "      <td>1354492800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 33898\\n# text = I have long, thin...</td>\n",
              "      <td>[i have long thin hair that be dry from highli...</td>\n",
              "      <td>[, , ]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 1, 2013</td>\n",
              "      <td>AS9FKELRT3NOD</td>\n",
              "      <td>B000YBNL2Y</td>\n",
              "      <td>{'Color:': ' Natural'}</td>\n",
              "      <td>annette galles</td>\n",
              "      <td>It is a fantastic product. I am happy with it ...</td>\n",
              "      <td>Love the product!</td>\n",
              "      <td>1383264000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[# sent_id = 33901\\n# text = It is a fantastic...</td>\n",
              "      <td>[-PRON- be a fantastic product, i be happy wit...</td>\n",
              "      <td>[, , ]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      overall  verified   reviewTime  ... synt_roles     POS morph_features\n",
              "0         2.0      True  08 18, 2015  ...         []      []             []\n",
              "1         5.0      True   03 8, 2015  ...         []      []             []\n",
              "2         5.0      True   11 1, 2013  ...      [obj]  [NOUN]  [Number=Sing]\n",
              "3         5.0      True  09 13, 2017  ...         []      []             []\n",
              "4         5.0      True   04 3, 2012  ...      [obj]  [NOUN]  [Number=Sing]\n",
              "...       ...       ...          ...  ...        ...     ...            ...\n",
              "9995      5.0      True  11 23, 2014  ...         []      []             []\n",
              "9996      5.0      True  10 17, 2017  ...         []      []             []\n",
              "9997      5.0      True  08 18, 2010  ...         []      []             []\n",
              "9998      5.0      True   12 3, 2012  ...         []      []             []\n",
              "9999      5.0      True   11 1, 2013  ...         []      []             []\n",
              "\n",
              "[10000 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y32OJ14WA23"
      },
      "source": [
        "### n-граммы с полученными сущностями"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwPMg8JhQuYA",
        "outputId": "a08c4832-65f8-4dda-c5ad-353438380af0"
      },
      "source": [
        "ngrams_all = []\n",
        "nes_all = []\n",
        "bigrams_per_text = []\n",
        "for index, row in tqdm(df.iterrows()):\n",
        "  bigrams = []\n",
        "  if row['NE'] != []:\n",
        "    bigrm = list(nltk.bigrams(row['reviewText'].split()))\n",
        "    for bi in bigrm:\n",
        "      for ne in row['NE']:\n",
        "        if ne in bi:\n",
        "          nes_all.append(ne)\n",
        "          ngrams_all.append(bi)\n",
        "          bigrams.append(bi[0] + ' ' + bi[1])\n",
        "  \n",
        "  bigrams_per_text.append(bigrams)\n",
        "\n",
        "df['bigrams'] = bigrams_per_text"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [00:02, 4742.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV1peUpqWJ_e"
      },
      "source": [
        "### PMI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeumrGvDfAet"
      },
      "source": [
        "texts = list(df.reviewText)\n",
        "texts = [str(text) for text in texts]\n",
        "texts_all = ' '.join(texts)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRL4bLFTaJ_A",
        "outputId": "2d35f5f1-01c8-4811-870a-dda0c839c9b1"
      },
      "source": [
        "best_pmi = []\n",
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "finder = BigramCollocationFinder.from_words(texts_all.split())\n",
        "finder.apply_freq_filter(5)\n",
        "best_bgrams = finder.nbest(bigram_measures.pmi, 5000)\n",
        "for bgram in best_bgrams:\n",
        "  if bgram in ngrams_all:\n",
        "    best_pmi.append(bgram)\n",
        "\n",
        "best_pmi[:10]"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Seche', 'Vite'),\n",
              " ('Pur', 'Minerals'),\n",
              " ('Top', 'Coat'),\n",
              " ('Calvin', 'Klein'),\n",
              " ('Nano', 'Titanium'),\n",
              " ('La', 'Roche-Posay'),\n",
              " ('Butter', 'London'),\n",
              " ('Hot', 'Tools'),\n",
              " ('Jane', 'Iredale'),\n",
              " ('Jack', 'Black')]"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk4Z5BGhhFFq"
      },
      "source": [
        "### likelihood ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8kvaenMg7at",
        "outputId": "1882ad27-0178-4d35-eca7-7758284a4afb"
      },
      "source": [
        "best_likelihood = []\n",
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "finder = BigramCollocationFinder.from_words(texts_all.split())\n",
        "finder.apply_freq_filter(5)\n",
        "best_bgrams = finder.nbest(bigram_measures.likelihood_ratio, 5000)\n",
        "for bgram in best_bgrams:\n",
        "  if bgram in ngrams_all:\n",
        "    best_likelihood.append(bgram)\n",
        "\n",
        "best_likelihood[:10]"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('my', 'hair'),\n",
              " ('this', 'product'),\n",
              " ('I', 'love'),\n",
              " ('my', 'skin'),\n",
              " ('a', 'little'),\n",
              " ('my', 'face'),\n",
              " ('a', 'lot'),\n",
              " ('love', 'this'),\n",
              " ('a', 'few'),\n",
              " ('a', 'bit')]"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY4tGMOthiG4"
      },
      "source": [
        "### raw freq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DbYl5BmhQn-",
        "outputId": "f3e012f5-0cd9-49c9-89bb-cdaafa113b36"
      },
      "source": [
        "best_raw_freq = []\n",
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "finder = BigramCollocationFinder.from_words(texts_all.split())\n",
        "finder.apply_freq_filter(5)\n",
        "best_bgrams = finder.nbest(bigram_measures.raw_freq, 5000)\n",
        "for bgram in best_bgrams:\n",
        "  if bgram in ngrams_all:\n",
        "    best_raw_freq.append(bgram)\n",
        "\n",
        "best_raw_freq[:10]"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('my', 'hair'),\n",
              " ('I', 'love'),\n",
              " ('this', 'product'),\n",
              " ('my', 'skin'),\n",
              " ('a', 'little'),\n",
              " ('this', 'is'),\n",
              " ('love', 'this'),\n",
              " ('my', 'face'),\n",
              " ('using', 'this'),\n",
              " ('the', 'product')]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWjtivkniCDU"
      },
      "source": [
        "Кажется, лучше всех справляется PMI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs1L_LMgiQMQ"
      },
      "source": [
        "### Сгруппируем полученные коллокации по NE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdlVZcYlj8s_"
      },
      "source": [
        "products = ['lotion', 'brush', 'polish', 'oil', 'dryer']"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1rRjhfUiZ2n",
        "outputId": "7205ac49-3108-446e-eaf7-5f0999e22f09"
      },
      "source": [
        "for product in products:\n",
        "  print(product)\n",
        "  print('---')\n",
        "  for col in best_pmi:\n",
        "    if product in col:\n",
        "      print(' '.join(col))\n",
        "  print('\\n')"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lotion\n",
            "---\n",
            "drying lotion\n",
            "facial lotion\n",
            "best lotion\n",
            "The lotion\n",
            "\n",
            "\n",
            "brush\n",
            "---\n",
            "round brush\n",
            "brush heads\n",
            "brush head\n",
            "shaving brush\n",
            "The brush\n",
            "\n",
            "\n",
            "polish\n",
            "---\n",
            "nail polish\n",
            "\n",
            "\n",
            "oil\n",
            "---\n",
            "coconut oil\n",
            "pre-shave oil\n",
            "Moroccan oil\n",
            "oil based\n",
            "an oil\n",
            "\n",
            "\n",
            "dryer\n",
            "---\n",
            "blow dryer\n",
            "hair dryer\n",
            "dryer I've\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEXUf5JCqKEK"
      },
      "source": [
        "### Cпособ объединить синонимичные упоминания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoaRpnn3qTCp"
      },
      "source": [
        "* Кажется, проблему объединения \"watch\" и \"smartwatch\" можно решить даже регулярками. А можно, например, посмотреть на близость их эмбеддингов.\n",
        "* Проблему с watch и Samsung Galaxy Watch можно решить с помощью синтаксических зависимостей: так будет выглядеть разметка UDPipe для предложения \"I've bought myself Samsung Galaxy Watch\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhKV1QZOn3HM",
        "outputId": "23c0bf7f-330a-4f77-9f6a-379713a0cf3d"
      },
      "source": [
        "print(\"\"\"# generator = UDPipe 2, https://lindat.mff.cuni.cz/services/udpipe\n",
        "# udpipe_model = english-gum-ud-2.6-200830\n",
        "# udpipe_model_licence = CC BY-NC-SA\n",
        "# newdoc\n",
        "# newpar\n",
        "# sent_id = 1\n",
        "# text = I've bought myself Samsung Galaxy Watch\n",
        "1\tI\tI\tPRON\tPRP\tCase=Nom|Number=Sing|Person=1|PronType=Prs\t3\tnsubj\t_\tSpaceAfter=No|TokenRange=0:1\n",
        "2\t've\thave\tAUX\tVBP\tMood=Ind|Tense=Pres|VerbForm=Fin\t3\taux\t_\tTokenRange=1:4\n",
        "3\tbought\tbuy\tVERB\tVBN\tTense=Past|VerbForm=Part\t0\troot\t_\tTokenRange=5:11\n",
        "4\tmyself\tmyself\tPRON\tPRP\tCase=Acc|Number=Sing|Person=1|PronType=Prs|Reflex=Yes\t3\tiobj\t_\tTokenRange=12:18\n",
        "5\tSamsung\tSamsung\tPROPN\tNNP\tNumber=Sing\t7\tcompound\t_\tTokenRange=19:26\n",
        "6\tGalaxy\tGalaxy\tPROPN\tNNP\tNumber=Sing\t7\tcompound\t_\tTokenRange=27:33\n",
        "7\tWatch\tWatch\tPROPN\tNNP\tNumber=Sing\t3\tobj\t_\tSpaceAfter=No|TokenRange=34:39\n",
        "\"\"\")"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# generator = UDPipe 2, https://lindat.mff.cuni.cz/services/udpipe\n",
            "# udpipe_model = english-gum-ud-2.6-200830\n",
            "# udpipe_model_licence = CC BY-NC-SA\n",
            "# newdoc\n",
            "# newpar\n",
            "# sent_id = 1\n",
            "# text = I've bought myself Samsung Galaxy Watch\n",
            "1\tI\tI\tPRON\tPRP\tCase=Nom|Number=Sing|Person=1|PronType=Prs\t3\tnsubj\t_\tSpaceAfter=No|TokenRange=0:1\n",
            "2\t've\thave\tAUX\tVBP\tMood=Ind|Tense=Pres|VerbForm=Fin\t3\taux\t_\tTokenRange=1:4\n",
            "3\tbought\tbuy\tVERB\tVBN\tTense=Past|VerbForm=Part\t0\troot\t_\tTokenRange=5:11\n",
            "4\tmyself\tmyself\tPRON\tPRP\tCase=Acc|Number=Sing|Person=1|PronType=Prs|Reflex=Yes\t3\tiobj\t_\tTokenRange=12:18\n",
            "5\tSamsung\tSamsung\tPROPN\tNNP\tNumber=Sing\t7\tcompound\t_\tTokenRange=19:26\n",
            "6\tGalaxy\tGalaxy\tPROPN\tNNP\tNumber=Sing\t7\tcompound\t_\tTokenRange=27:33\n",
            "7\tWatch\tWatch\tPROPN\tNNP\tNumber=Sing\t3\tobj\t_\tSpaceAfter=No|TokenRange=34:39\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjtbGxbzsA3Q"
      },
      "source": [
        "Здесь мы видим, что слова samsung и galaxy зависят от их вершины watch и являются кампаундом. То есть мы могли бы спокойно написать правило, извлекающее такие и другие похожие конструкции для товаров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN-COLr_rYpg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
